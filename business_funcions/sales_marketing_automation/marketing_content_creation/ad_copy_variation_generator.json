{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-uyxiX",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-rEVVO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-uyxiX{œdataTypeœ:œChatInputœ,œidœ:œChatInput-uyxiXœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-rEVVO{œfieldNameœ:œinput_valueœ,œidœ:œAgent-rEVVOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-uyxiX",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-uyxiXœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-rEVVO",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-rEVVOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-rEVVO",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "SmartRouter-nOpg1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Agent-rEVVO{œdataTypeœ:œAgentœ,œidœ:œAgent-rEVVOœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-SmartRouter-nOpg1{œfieldNameœ:œinput_textœ,œidœ:œSmartRouter-nOpg1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-rEVVO",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-rEVVOœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SmartRouter-nOpg1",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œSmartRouter-nOpg1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SmartRouter",
            "id": "SmartRouter-nOpg1",
            "name": "category_2_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Ujq5T",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SmartRouter-nOpg1{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_2_resultœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Ujq5T{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ujq5Tœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SmartRouter-nOpg1",
        "sourceHandle": "{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_2_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Ujq5T",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ujq5Tœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SmartRouter",
            "id": "SmartRouter-nOpg1",
            "name": "category_1_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutput-2RGtf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__SmartRouter-nOpg1{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_1_resultœ,œoutput_typesœ:[œMessageœ]}-StructuredOutput-2RGtf{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutput-2RGtfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "SmartRouter-nOpg1",
        "sourceHandle": "{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_1_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StructuredOutput-2RGtf",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutput-2RGtfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutput",
            "id": "StructuredOutput-2RGtf",
            "name": "dataframe_output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-LXFUl",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__StructuredOutput-2RGtf{œdataTypeœ:œStructuredOutputœ,œidœ:œStructuredOutput-2RGtfœ,œnameœ:œdataframe_outputœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-LXFUl{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-LXFUlœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "StructuredOutput-2RGtf",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputœ,œidœ:œStructuredOutput-2RGtfœ,œnameœ:œdataframe_outputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-LXFUl",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-LXFUlœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-LXFUl",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "platform",
            "id": "Prompt Template-NuOku",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-LXFUl{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-LXFUlœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-NuOku{œfieldNameœ:œplatformœ,œidœ:œPrompt Template-NuOkuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-LXFUl",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-LXFUlœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-NuOku",
        "targetHandle": "{œfieldNameœ:œplatformœ,œidœ:œPrompt Template-NuOkuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SmartRouter",
            "id": "SmartRouter-nOpg1",
            "name": "category_1_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt Template-NuOku",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__SmartRouter-nOpg1{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_1_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-NuOku{œfieldNameœ:œcontextœ,œidœ:œPrompt Template-NuOkuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "SmartRouter-nOpg1",
        "sourceHandle": "{œdataTypeœ:œSmartRouterœ,œidœ:œSmartRouter-nOpg1œ,œnameœ:œcategory_1_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-NuOku",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt Template-NuOkuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-NuOku",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-jHQx9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-NuOku{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-NuOkuœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-jHQx9{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-NuOku",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-NuOkuœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-jHQx9",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UnifiedWebSearch",
            "id": "UnifiedWebSearch-TIllK",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-jHQx9",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UnifiedWebSearch-TIllK{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-TIllKœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-jHQx9{œfieldNameœ:œtoolsœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UnifiedWebSearch-TIllK",
        "sourceHandle": "{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-TIllKœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-jHQx9",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CurrentDate",
            "id": "CurrentDate-zvJtP",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-jHQx9",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CurrentDate-zvJtP{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-zvJtPœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-jHQx9{œfieldNameœ:œtoolsœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CurrentDate-zvJtP",
        "sourceHandle": "{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-zvJtPœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-jHQx9",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-jHQx9œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-jHQx9",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-9skbh",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-jHQx9{œdataTypeœ:œAgentœ,œidœ:œAgent-jHQx9œ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-9skbh{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9skbhœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-jHQx9",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-jHQx9œ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-9skbh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9skbhœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-uyxiX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "7a26c54d89ed",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        # Filter out None/empty values\n        files = [f for f in files if f is not None and f != \"\"]\n\n        session_id = self.session_id or self.graph.session_id or \"\"\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=session_id,\n            context_id=self.context_id,\n            files=files,\n        )\n        if session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-uyxiX",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": -455.79728145141615,
          "y": 338.08586927650106
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Ujq5T",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.128.0"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Ujq5T",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 764.0864538024368,
          "y": 552.1166175621393
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-rEVVO",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent Collector",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-27T01:48:36.470Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "bdc309bc2d2a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.81"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "input_types": [],
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "input_types": [],
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import ValidationError\n\nfrom lfx.components.models_and_agents.memory import MemoryComponent\n\nif TYPE_CHECKING:\n    from langchain_core.tools import Tool\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, ModelInput\nfrom lfx.io import IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        from langchain_core.tools import StructuredTool\n\n        llm_model = get_llm(\n            model=self.model,\n            user_id=self.user_id,\n            api_key=self.api_key,\n        )\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: list[dict],\n        field_name: str | None = None,\n    ) -> dotdict:\n        # Update model options with caching (for all field changes)\n        # Agents require tool calling, so filter for only tool-calling capable models\n        def get_tool_calling_model_options(user_id=None):\n            return get_language_model_options(user_id=user_id, tool_calling=True)\n\n        build_config = update_model_options_in_build_config(\n            component=self,\n            build_config=dict(build_config),\n            cache_key_prefix=\"language_model_options_tool_calling\",\n            get_options_func=get_tool_calling_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n        build_config = dotdict(build_config)\n\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        if field_name == \"model\":\n            self.log(str(field_value))\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"model\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-pro",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash-8b",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-lite",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.3",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "qwq",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.2",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.1",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "mistral",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-2b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-8b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-13b-instruct-v2",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  }
                ]
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an information gathering agent for an ad copywriting system. Your job is to collect the necessary information from the user to generate ad copy variations.\n\nCollect the following information:\n- Product: What product or service is being advertised\n- Target Audience: Who the ad is aimed at\n- Benefits: Key benefits or value propositions to highlight\n- Tone of Voice: Desired tone (professional, casual, urgent, friendly, etc.)\n- Platform: Advertising platform (Google Ads, Facebook Ads, Instagram, LinkedIn, etc.)\n- Number of Variations: How many ad variations to generate\n\nAttempt to collect all information in a single message by asking a clear, structured question that prompts the user to provide all details at once.\n\nOnce you have collected all six pieces of information, output them in this exact format:\nProduct: {product}\nTarget Audience: {target_audience}\nBenefits: {benefits}\nTone of Voice: {tone_of_voice}\nPlatform: {platform}\nNumber of Variations: {number_of_variations}\n\nIf any information is missing, ask the user specific follow-up questions until you have everything. Do not proceed to the formatted output until all six fields are complete.\n\nYour final output should contain ONLY the formatted information above, nothing else."
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-rEVVO",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": -138.27134873293738,
          "y": -71.0956386168786
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SmartRouter-nOpg1",
          "node": {
            "base_classes": [],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message using LLM-based categorization.",
            "display_name": "Smart Router",
            "documentation": "",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "input_text",
              "routes",
              "message",
              "enable_else_output",
              "custom_prompt"
            ],
            "frozen": false,
            "icon": "route",
            "last_updated": "2026-01-27T01:48:00.454Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "9c6736e784f6",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.llm_operations.llm_conditional_router.SmartRouterComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Generate Variation",
                "group_outputs": true,
                "hidden": null,
                "loop_types": null,
                "method": "process_case",
                "name": "category_1_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Colect information",
                "group_outputs": true,
                "hidden": null,
                "loop_types": null,
                "method": "process_case",
                "name": "category_2_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.custom import Component\nfrom lfx.io import (\n    BoolInput,\n    MessageInput,\n    MessageTextInput,\n    ModelInput,\n    MultilineInput,\n    Output,\n    SecretStrInput,\n    TableInput,\n)\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\nclass SmartRouterComponent(Component):\n    display_name = \"Smart Router\"\n    description = \"Routes an input message using LLM-based categorization.\"\n    icon = \"route\"\n    name = \"SmartRouter\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._matched_category = None\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        TableInput(\n            name=\"routes\",\n            display_name=\"Routes\",\n            info=(\n                \"Define the categories for routing. Each row should have a route/category name \"\n                \"and optionally a custom output value.\"\n            ),\n            table_schema=[\n                {\n                    \"name\": \"route_category\",\n                    \"display_name\": \"Route Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Name for the route (used for both output name and category matching)\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"route_description\",\n                    \"display_name\": \"Route Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Description of when this route should be used (helps LLM understand the category)\",\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"output_value\",\n                    \"display_name\": \"Route Message (Optional)\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Optional message to send when this route is matched.\"\n                        \"Leave empty to pass through the original input text.\"\n                    ),\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n            ],\n            value=[\n                {\n                    \"route_category\": \"Positive\",\n                    \"route_description\": \"Positive feedback, satisfaction, or compliments\",\n                    \"output_value\": \"\",\n                },\n                {\n                    \"route_category\": \"Negative\",\n                    \"route_description\": \"Complaints, issues, or dissatisfaction\",\n                    \"output_value\": \"\",\n                },\n            ],\n            real_time_refresh=True,\n            required=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Override Output\",\n            info=(\n                \"Optional override message that will replace both the Input and Output Value \"\n                \"for all routes when filled.\"\n            ),\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_else_output\",\n            display_name=\"Include Else Output\",\n            info=\"Include an Else output for cases that don't match any route.\",\n            value=False,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"custom_prompt\",\n            display_name=\"Additional Instructions\",\n            info=(\n                \"Additional instructions for LLM-based categorization. \"\n                \"These will be added to the base prompt. \"\n                \"Use {input_text} for the input text and {routes} for the available categories.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs: list[Output] = []\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        \"\"\"Dynamically update build config with user-filtered model options.\"\"\"\n        return update_model_options_in_build_config(\n            component=self,\n            build_config=build_config,\n            cache_key_prefix=\"language_model_options\",\n            get_options_func=get_language_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Create a dynamic output for each category in the categories table.\"\"\"\n        if field_name in {\"routes\", \"enable_else_output\"}:\n            frontend_node[\"outputs\"] = []\n\n            # Get the routes data - either from field_value (if routes field) or from component state\n            routes_data = field_value if field_name == \"routes\" else getattr(self, \"routes\", [])\n\n            # Add a dynamic output for each category - all using the same method\n            for i, row in enumerate(routes_data):\n                route_category = row.get(\"route_category\", f\"Category {i + 1}\")\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=route_category,\n                        name=f\"category_{i + 1}_result\",\n                        method=\"process_case\",\n                        group_outputs=True,\n                    )\n                )\n            # Add default output only if enabled\n            if field_name == \"enable_else_output\":\n                enable_else = field_value\n            else:\n                enable_else = getattr(self, \"enable_else_output\", False)\n\n            if enable_else:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Else\", name=\"default_result\", method=\"default_response\", group_outputs=True)\n                )\n        return frontend_node\n\n    def process_case(self) -> Message:\n        \"\"\"Process all categories using LLM categorization and return message for matching category.\"\"\"\n        # Clear any previous match state\n        self._matched_category = None\n\n        # Get categories and input text\n        categories = getattr(self, \"routes\", [])\n        input_text = getattr(self, \"input_text\", \"\")\n\n        # Find the matching category using LLM-based categorization\n        matched_category = None\n        llm = get_llm(model=self.model, user_id=self.user_id, api_key=self.api_key)\n\n        if llm and categories:\n            # Create prompt for categorization\n            category_info = []\n            for i, category in enumerate(categories):\n                cat_name = category.get(\"route_category\", f\"Category {i + 1}\")\n                cat_desc = category.get(\"route_description\", \"\")\n                if cat_desc and cat_desc.strip():\n                    category_info.append(f'\"{cat_name}\": {cat_desc}')\n                else:\n                    category_info.append(f'\"{cat_name}\"')\n\n            categories_text = \"\\n\".join([f\"- {info}\" for info in category_info if info])\n\n            # Create base prompt\n            base_prompt = (\n                f\"You are a text classifier. Given the following text and categories, \"\n                f\"determine which category best matches the text.\\n\\n\"\n                f'Text to classify: \"{input_text}\"\\n\\n'\n                f\"Available categories:\\n{categories_text}\\n\\n\"\n                f\"Respond with ONLY the exact category name that best matches the text. \"\n                f'If none match well, respond with \"NONE\".\\n\\n'\n                f\"Category:\"\n            )\n\n            # Use custom prompt as additional instructions if provided\n            custom_prompt = getattr(self, \"custom_prompt\", \"\")\n            if custom_prompt and custom_prompt.strip():\n                self.status = \"Using custom prompt as additional instructions\"\n                # Format custom prompt with variables\n                # For the routes variable, create a simpler format for custom prompt usage\n                simple_routes = \", \".join(\n                    [f'\"{cat.get(\"route_category\", f\"Category {i + 1}\")}\"' for i, cat in enumerate(categories)]\n                )\n                formatted_custom = custom_prompt.format(input_text=input_text, routes=simple_routes)\n                # Combine base prompt with custom instructions\n                prompt = f\"{base_prompt}\\n\\nAdditional Instructions:\\n{formatted_custom}\"\n            else:\n                self.status = \"Using default prompt for LLM categorization\"\n                prompt = base_prompt\n\n            # Log the final prompt being sent to LLM\n            self.status = f\"Prompt sent to LLM:\\n{prompt}\"\n\n            try:\n                # Use the LLM to categorize\n                if hasattr(llm, \"invoke\"):\n                    response = llm.invoke(prompt)\n                    if hasattr(response, \"content\"):\n                        categorization = response.content.strip().strip('\"')\n                    else:\n                        categorization = str(response).strip().strip('\"')\n                else:\n                    categorization = str(llm(prompt)).strip().strip('\"')\n\n                # Log the categorization process\n                self.status = f\"LLM response: '{categorization}'\"\n\n                # Find matching category based on LLM response\n                for i, category in enumerate(categories):\n                    route_category = category.get(\"route_category\", \"\")\n\n                    # Log each comparison attempt\n                    self.status = (\n                        f\"Comparing '{categorization}' with category {i + 1}: route_category='{route_category}'\"\n                    )\n\n                    # Case-insensitive match\n                    if categorization.lower() == route_category.lower():\n                        matched_category = i\n                        self.status = f\"MATCH FOUND! Category {i + 1} matched with '{categorization}'\"\n                        break\n\n                if matched_category is None:\n                    self.status = (\n                        f\"No match found for '{categorization}'. Available categories: \"\n                        f\"{[category.get('route_category', '') for category in categories]}\"\n                    )\n\n            except RuntimeError as e:\n                self.status = f\"Error in LLM categorization: {e!s}\"\n        else:\n            self.status = \"No LLM provided for categorization\"\n\n        if matched_category is not None:\n            # Store the matched category for other outputs to check\n            self._matched_category = matched_category\n\n            # Stop all category outputs except the matched one\n            for i in range(len(categories)):\n                if i != matched_category:\n                    self.stop(f\"category_{i + 1}_result\")\n\n            # Also stop the default output (if it exists)\n            enable_else = getattr(self, \"enable_else_output\", False)\n            if enable_else:\n                self.stop(\"default_result\")\n\n            route_category = categories[matched_category].get(\"route_category\", f\"Category {matched_category + 1}\")\n            self.status = f\"Categorized as {route_category}\"\n\n            # Check if there's an override output (takes precedence over everything)\n            override_output = getattr(self, \"message\", None)\n            if (\n                override_output\n                and hasattr(override_output, \"text\")\n                and override_output.text\n                and str(override_output.text).strip()\n            ):\n                return Message(text=str(override_output.text))\n            if override_output and isinstance(override_output, str) and override_output.strip():\n                return Message(text=str(override_output))\n\n            # Check if there's a custom output value for this category\n            custom_output = categories[matched_category].get(\"output_value\", \"\")\n            # Treat None, empty string, or whitespace as blank\n            if custom_output and str(custom_output).strip() and str(custom_output).strip().lower() != \"none\":\n                # Use custom output value\n                return Message(text=str(custom_output))\n            # Use input as default output\n            return Message(text=input_text)\n        # No match found, stop all category outputs\n        for i in range(len(categories)):\n            self.stop(f\"category_{i + 1}_result\")\n\n        # Check if else output is enabled\n        enable_else = getattr(self, \"enable_else_output\", False)\n        if enable_else:\n            # The default_response will handle the else case\n            self.stop(\"process_case\")\n            return Message(text=\"\")\n        # No else output, so no output at all\n        self.status = \"No match found and Else output is disabled\"\n        return Message(text=\"\")\n\n    def default_response(self) -> Message:\n        \"\"\"Handle the else case when no conditions match.\"\"\"\n        # Check if else output is enabled\n        enable_else = getattr(self, \"enable_else_output\", False)\n        if not enable_else:\n            self.status = \"Else output is disabled\"\n            return Message(text=\"\")\n\n        # Clear any previous match state if not already set\n        if not hasattr(self, \"_matched_category\"):\n            self._matched_category = None\n\n        categories = getattr(self, \"routes\", [])\n        input_text = getattr(self, \"input_text\", \"\")\n\n        # Check if a match was already found in process_case\n        if hasattr(self, \"_matched_category\") and self._matched_category is not None:\n            self.status = (\n                f\"Match already found in process_case (Category {self._matched_category + 1}), \"\n                \"stopping default_response\"\n            )\n            self.stop(\"default_result\")\n            return Message(text=\"\")\n\n        # Check if any category matches using LLM categorization\n        has_match = False\n        llm = get_llm(model=self.model, user_id=self.user_id, api_key=self.api_key)\n\n        if llm and categories:\n            try:\n                # Create prompt for categorization\n                category_info = []\n                for i, category in enumerate(categories):\n                    cat_name = category.get(\"route_category\", f\"Category {i + 1}\")\n                    cat_desc = category.get(\"route_description\", \"\")\n                    if cat_desc and cat_desc.strip():\n                        category_info.append(f'\"{cat_name}\": {cat_desc}')\n                    else:\n                        category_info.append(f'\"{cat_name}\"')\n\n                categories_text = \"\\n\".join([f\"- {info}\" for info in category_info if info])\n\n                # Create base prompt\n                base_prompt = (\n                    \"You are a text classifier. Given the following text and categories, \"\n                    \"determine which category best matches the text.\\n\\n\"\n                    f'Text to classify: \"{input_text}\"\\n\\n'\n                    f\"Available categories:\\n{categories_text}\\n\\n\"\n                    \"Respond with ONLY the exact category name that best matches the text. \"\n                    'If none match well, respond with \"NONE\".\\n\\n'\n                    \"Category:\"\n                )\n\n                # Use custom prompt as additional instructions if provided\n                custom_prompt = getattr(self, \"custom_prompt\", \"\")\n                if custom_prompt and custom_prompt.strip():\n                    self.status = \"Using custom prompt as additional instructions (default check)\"\n                    # Format custom prompt with variables\n                    # For the routes variable, create a simpler format for custom prompt usage\n                    simple_routes = \", \".join(\n                        [f'\"{cat.get(\"route_category\", f\"Category {i + 1}\")}\"' for i, cat in enumerate(categories)]\n                    )\n                    formatted_custom = custom_prompt.format(input_text=input_text, routes=simple_routes)\n                    # Combine base prompt with custom instructions\n                    prompt = f\"{base_prompt}\\n\\nAdditional Instructions:\\n{formatted_custom}\"\n                else:\n                    self.status = \"Using default prompt for LLM categorization (default check)\"\n                    prompt = base_prompt\n\n                # Log the final prompt being sent to LLM for default check\n                self.status = f\"Default check - Prompt sent to LLM:\\n{prompt}\"\n\n                # Use the LLM to categorize\n                if hasattr(llm, \"invoke\"):\n                    response = llm.invoke(prompt)\n                    if hasattr(response, \"content\"):\n                        categorization = response.content.strip().strip('\"')\n                    else:\n                        categorization = str(response).strip().strip('\"')\n                else:\n                    categorization = str(llm(prompt)).strip().strip('\"')\n\n                # Log the categorization process for default check\n                self.status = f\"Default check - LLM response: '{categorization}'\"\n\n                # Check if LLM response matches any category\n                for i, category in enumerate(categories):\n                    route_category = category.get(\"route_category\", \"\")\n\n                    # Log each comparison attempt\n                    self.status = (\n                        f\"Default check - Comparing '{categorization}' with category {i + 1}: \"\n                        f\"route_category='{route_category}'\"\n                    )\n\n                    if categorization.lower() == route_category.lower():\n                        has_match = True\n                        self.status = f\"Default check - MATCH FOUND! Category {i + 1} matched with '{categorization}'\"\n                        break\n\n                if not has_match:\n                    self.status = (\n                        f\"Default check - No match found for '{categorization}'. \"\n                        f\"Available categories: \"\n                        f\"{[category.get('route_category', '') for category in categories]}\"\n                    )\n\n            except RuntimeError:\n                pass  # If there's an error, treat as no match\n\n        if has_match:\n            # A case matches, stop this output\n            self.stop(\"default_result\")\n            return Message(text=\"\")\n\n        # No case matches, check for override output first, then use input as default\n        override_output = getattr(self, \"message\", None)\n        if (\n            override_output\n            and hasattr(override_output, \"text\")\n            and override_output.text\n            and str(override_output.text).strip()\n        ):\n            self.status = \"Routed to Else (no match) - using override output\"\n            return Message(text=str(override_output.text))\n        if override_output and isinstance(override_output, str) and override_output.strip():\n            self.status = \"Routed to Else (no match) - using override output\"\n            return Message(text=str(override_output))\n        self.status = \"Routed to Else (no match) - using input as default\"\n        return Message(text=input_text)\n"
              },
              "custom_prompt": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Additional Instructions",
                "dynamic": false,
                "info": "Additional instructions for LLM-based categorization. These will be added to the base prompt. Use {input_text} for the input text and {routes} for the available categories.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "custom_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "enable_else_output": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include Else Output",
                "dynamic": false,
                "info": "Include an Else output for cases that don't match any route.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_else_output",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Override Output",
                "dynamic": false,
                "info": "Optional override message that will replace both the Input and Output Value for all routes when filled.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-chat-latest"
                      ]
                    },
                    "name": "gpt-5-chat-latest",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "o1"
                      ]
                    },
                    "name": "o1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-pro",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash-8b",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-lite",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.3",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "qwq",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.2",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.1",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "mistral",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-2b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-8b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-13b-instruct-v2",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  }
                ]
              },
              "routes": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Routes",
                "dynamic": false,
                "info": "Define the categories for routing. Each row should have a route/category name and optionally a custom output value.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "routes",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "description": "Name for the route (used for both output name and category matching)",
                    "display_name": "Route Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "route_category",
                    "type": "str"
                  },
                  {
                    "default": "",
                    "description": "Description of when this route should be used (helps LLM understand the category)",
                    "display_name": "Route Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "route_description",
                    "type": "str"
                  },
                  {
                    "default": "",
                    "description": "Optional message to send when this route is matched.Leave empty to pass through the original input text.",
                    "display_name": "Route Message (Optional)",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "output_value",
                    "type": "str"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "output_value": "",
                    "route_category": "Generate Variation",
                    "route_description": "The message follows the structure below: Product: {product} Target Audience: {target_audience} Benefits: {benefits} Tone of Voice: {tone} Platform: {platform} Number of Variation: {number_of_variation}"
                  },
                  {
                    "output_value": "",
                    "route_category": "Colect information",
                    "route_description": "The message needs more information"
                  }
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SmartRouter"
        },
        "dragging": false,
        "id": "SmartRouter-nOpg1",
        "measured": {
          "height": 431,
          "width": 320
        },
        "position": {
          "x": 253.8929016083959,
          "y": 50.63701242547491
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-jHQx9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent Generator",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-27T02:26:34.410Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "bdc309bc2d2a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.81"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "input_types": [],
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "input_types": [],
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import ValidationError\n\nfrom lfx.components.models_and_agents.memory import MemoryComponent\n\nif TYPE_CHECKING:\n    from langchain_core.tools import Tool\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, ModelInput\nfrom lfx.io import IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        from langchain_core.tools import StructuredTool\n\n        llm_model = get_llm(\n            model=self.model,\n            user_id=self.user_id,\n            api_key=self.api_key,\n        )\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: list[dict],\n        field_name: str | None = None,\n    ) -> dotdict:\n        # Update model options with caching (for all field changes)\n        # Agents require tool calling, so filter for only tool-calling capable models\n        def get_tool_calling_model_options(user_id=None):\n            return get_language_model_options(user_id=user_id, tool_calling=True)\n\n        build_config = update_model_options_in_build_config(\n            component=self,\n            build_config=dict(build_config),\n            cache_key_prefix=\"language_model_options_tool_calling\",\n            get_options_func=get_tool_calling_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n        build_config = dotdict(build_config)\n\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        if field_name == \"model\":\n            self.log(str(field_value))\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"model\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-pro",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash-8b",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-lite",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.3",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "qwq",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.2",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.1",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "mistral",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-2b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-8b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-13b-instruct-v2",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  }
                ]
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "O seu trabalho é coletar informações para um copywriter gerar variacoes de anuncios. Pergunte ao usuário sobre como é o anuncio que ele quer gerar, coletando as seguintes informacoees:\n\nProduct: \nTarget Audience: \nBenefits: \nTone of Voice: \nPlatform:\nNumber of Variation:\n\nTente coletar tudo em uma unica mensagem. quando voce tiver com todas as informacoes estruturadas, gere o output formatado nessa ordem. o seu output final deve conter somente as informacoes:\n\nProduct: {product}\nTarget Audience: {target_audience}\nBenefits: {benefits}\nTone of Voice: {tone_of_voice}\nPlatform: {platform}\nNumber of Variation: {number_of_variation}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-jHQx9",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": 2084.4487478604483,
          "y": -162.19312477445138
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "StructuredOutput-2RGtf",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Uses an LLM to generate structured data. Ideal for extraction and consistency.",
            "display_name": "Structured Output",
            "documentation": "https://docs.langflow.org/structured-output",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "input_value",
              "system_prompt",
              "schema_name",
              "output_schema"
            ],
            "frozen": false,
            "icon": "braces",
            "last_updated": "2026-01-27T01:58:28.926Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "058ca1f51e9f",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "trustcall",
                    "version": "0.0.39"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.llm_operations.structured_output.StructuredOutputComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Output",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_structured_output",
                "name": "structured_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Output",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_structured_dataframe",
                "name": "dataframe_output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic import BaseModel, Field, create_model\nfrom trustcall import create_extractor\n\nfrom lfx.base.models.chat_result import get_chat_result\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.io import (\n    MessageTextInput,\n    ModelInput,\n    MultilineInput,\n    Output,\n    SecretStrInput,\n    TableInput,\n)\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.table import EditMode\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = \"Uses an LLM to generate structured data. Ideal for extraction and consistency.\"\n    documentation: str = \"https://docs.langflow.org/structured-output\"\n    name = \"StructuredOutput\"\n    icon = \"braces\"\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Message\",\n            info=\"The input message to the language model.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Format Instructions\",\n            info=\"The instructions to the language model for formatting the output.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            required=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            required=True,\n            # TODO: remove deault value\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"name\": \"field\",\n                    \"description\": \"description of field\",\n                    \"type\": \"str\",\n                    \"multiple\": \"False\",\n                }\n            ],\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"structured_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_output\",\n        ),\n        Output(\n            name=\"dataframe_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_dataframe\",\n        ),\n    ]\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        \"\"\"Dynamically update build config with user-filtered model options.\"\"\"\n        return update_model_options_in_build_config(\n            component=self,\n            build_config=build_config,\n            cache_key_prefix=\"language_model_options\",\n            get_options_func=get_language_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n\n    def build_structured_output_base(self):\n        schema_name = self.schema_name or \"OutputModel\"\n\n        llm = get_llm(model=self.model, user_id=self.user_id, api_key=self.api_key)\n\n        if not hasattr(llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        output_model_ = build_model_from_schema(self.output_schema)\n        output_model = create_model(\n            schema_name,\n            __doc__=f\"A list of {schema_name}.\",\n            objects=(\n                list[output_model_],\n                Field(\n                    description=f\"A list of {schema_name}.\",  # type: ignore[valid-type]\n                    min_length=1,  # help ensure non-empty output\n                ),\n            ),\n        )\n        # Tracing config\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        # Generate structured output using Trustcall first, then fallback to Langchain if it fails\n        result = self._extract_output_with_trustcall(llm, output_model, config_dict)\n        if result is None:\n            result = self._extract_output_with_langchain(llm, output_model, config_dict)\n\n        # OPTIMIZATION NOTE: Simplified processing based on trustcall response structure\n        # Handle non-dict responses (shouldn't happen with trustcall, but defensive)\n        if not isinstance(result, dict):\n            return result\n\n        # Extract first response and convert BaseModel to dict\n        responses = result.get(\"responses\", [])\n        if not responses:\n            return result\n\n        # Convert BaseModel to dict (creates the \"objects\" key)\n        first_response = responses[0]\n        structured_data = first_response\n        if isinstance(first_response, BaseModel):\n            structured_data = first_response.model_dump()\n        # Extract the objects array (guaranteed to exist due to our Pydantic model structure)\n        return structured_data.get(\"objects\", structured_data)\n\n    def build_structured_output(self) -> Data:\n        output = self.build_structured_output_base()\n        if not isinstance(output, list) or not output:\n            # handle empty or unexpected type case\n            msg = \"No structured output returned\"\n            raise ValueError(msg)\n        if len(output) == 1:\n            return Data(data=output[0])\n        if len(output) > 1:\n            # Multiple outputs - wrap them in a results container\n            return Data(data={\"results\": output})\n        return Data()\n\n    def build_structured_dataframe(self) -> DataFrame:\n        output = self.build_structured_output_base()\n        if not isinstance(output, list) or not output:\n            # handle empty or unexpected type case\n            msg = \"No structured output returned\"\n            raise ValueError(msg)\n        if len(output) == 1:\n            # For single dictionary, wrap in a list to create DataFrame with one row\n            return DataFrame([output[0]])\n        if len(output) > 1:\n            # Multiple outputs - convert to DataFrame directly\n            return DataFrame(output)\n        return DataFrame()\n\n    def _extract_output_with_trustcall(self, llm, schema: BaseModel, config_dict: dict) -> list[BaseModel] | None:\n        try:\n            llm_with_structured_output = create_extractor(llm, tools=[schema], tool_choice=schema.__name__)\n            result = get_chat_result(\n                runnable=llm_with_structured_output,\n                system_message=self.system_prompt,\n                input_value=self.input_value,\n                config=config_dict,\n            )\n        except Exception as e:  # noqa: BLE001\n            logger.warning(\n                f\"Trustcall extraction failed, falling back to Langchain: {e} \"\n                \"(Note: This may not be an error—some models or configurations do not support tool calling. \"\n                \"Falling back is normal in such cases.)\"\n            )\n            return None\n        return result or None  # langchain fallback is used if error occurs or the result is empty\n\n    def _extract_output_with_langchain(self, llm, schema: BaseModel, config_dict: dict) -> list[BaseModel] | None:\n        try:\n            llm_with_structured_output = llm.with_structured_output(schema)\n            result = get_chat_result(\n                runnable=llm_with_structured_output,\n                system_message=self.system_prompt,\n                input_value=self.input_value,\n                config=config_dict,\n            )\n            if isinstance(result, BaseModel):\n                result = result.model_dump()\n                result = result.get(\"objects\", result)\n        except Exception as fallback_error:\n            msg = (\n                f\"Model does not support tool calling (trustcall failed) \"\n                f\"and fallback with_structured_output also failed: {fallback_error}\"\n            )\n            raise ValueError(msg) from fallback_error\n\n        return result or None\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The input message to the language model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-chat-latest"
                      ]
                    },
                    "name": "gpt-5-chat-latest",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "o1"
                      ]
                    },
                    "name": "o1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-search-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-pro",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash-8b",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-lite",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 128000,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.3",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "qwq",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.2",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "llama3.1",
                    "provider": "Ollama"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "api_key_param": "base_url",
                      "base_url_param": "base_url",
                      "context_length": 128000,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "mistral",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-2b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-3-8b-instruct",
                    "provider": "IBM WatsonX"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "IBM",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 128000,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ibm/granite-13b-instruct-v2",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  }
                ]
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Define the structure and data types for the model's output.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "description": "description of field",
                    "multiple": "False",
                    "name": "platform",
                    "type": "str"
                  }
                ]
              },
              "schema_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Schema Name",
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "schema_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Format Instructions",
                "dynamic": false,
                "info": "The instructions to the language model for formatting the output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe_output",
          "showNode": true,
          "type": "StructuredOutput"
        },
        "dragging": false,
        "id": "StructuredOutput-2RGtf",
        "measured": {
          "height": 387,
          "width": 320
        },
        "position": {
          "x": 750.0141284181202,
          "y": -169.81079294306866
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-LXFUl",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "3cda25c3f7b5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.processing.parser.ParserComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            # Use format_map with a dict that returns default_value for missing keys\n            class DefaultDict(dict):\n                def __missing__(self, key):\n                    return data.default_value or \"\"\n\n            formatted_text = self.pattern.format_map(DefaultDict(data.data))\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{platform}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-LXFUl",
        "measured": {
          "height": 329,
          "width": 320
        },
        "position": {
          "x": 1164.603413837066,
          "y": -108.3004183768796
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-NuOku",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "platform",
                "context"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "use_double_brackets",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "595f7c9c8463",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.models_and_agents.prompt.PromptComponent"
            },
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom lfx.base.prompts.api_utils import process_prompt_template\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.input_mixin import FieldTypes\nfrom lfx.inputs.inputs import DefaultPromptField\nfrom lfx.io import BoolInput, MessageTextInput, Output, PromptInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.template.utils import update_template_values\nfrom lfx.utils.mustache_security import validate_mustache_template\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        BoolInput(\n            name=\"use_double_brackets\",\n            display_name=\"Use Double Brackets\",\n            value=False,\n            advanced=True,\n            info=\"Use {{variable}} syntax instead of {variable}.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update the template field type based on the selected mode.\"\"\"\n        if field_name == \"use_double_brackets\":\n            # Change the template field type based on mode\n            is_mustache = field_value is True\n            if is_mustache:\n                build_config[\"template\"][\"type\"] = FieldTypes.MUSTACHE_PROMPT.value\n            else:\n                build_config[\"template\"][\"type\"] = FieldTypes.PROMPT.value\n\n            # Re-process the template to update variables when mode changes\n            template_value = build_config.get(\"template\", {}).get(\"value\", \"\")\n            if template_value:\n                # Ensure custom_fields is properly initialized\n                if \"custom_fields\" not in build_config:\n                    build_config[\"custom_fields\"] = {}\n\n                # Clean up fields from the OLD mode before processing with NEW mode\n                # This ensures we don't keep fields with wrong syntax even if validation fails\n                old_custom_fields = build_config[\"custom_fields\"].get(\"template\", [])\n                for old_field in list(old_custom_fields):\n                    # Remove the field from custom_fields and template\n                    if old_field in old_custom_fields:\n                        old_custom_fields.remove(old_field)\n                    build_config.pop(old_field, None)\n\n                # Try to process template with new mode to add new variables\n                # If validation fails, at least we cleaned up old fields\n                try:\n                    # Validate mustache templates for security\n                    if is_mustache:\n                        validate_mustache_template(template_value)\n\n                    # Re-process template with new mode to add new variables\n                    _ = process_prompt_template(\n                        template=template_value,\n                        name=\"template\",\n                        custom_fields=build_config[\"custom_fields\"],\n                        frontend_node_template=build_config,\n                        is_mustache=is_mustache,\n                    )\n                except ValueError as e:\n                    # If validation fails, we still updated the mode and cleaned old fields\n                    # User will see error when they try to save\n                    logger.debug(f\"Template validation failed during mode switch: {e}\")\n        return build_config\n\n    async def build_prompt(self) -> Message:\n        use_double_brackets = self.use_double_brackets if hasattr(self, \"use_double_brackets\") else False\n        template_format = \"mustache\" if use_double_brackets else \"f-string\"\n        prompt = await Message.from_template_and_variables(template_format=template_format, **self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        use_double_brackets = frontend_node[\"template\"].get(\"use_double_brackets\", {}).get(\"value\", False)\n        is_mustache = use_double_brackets is True\n\n        try:\n            # Validate mustache templates for security\n            if is_mustache:\n                validate_mustache_template(prompt_template)\n\n            custom_fields = frontend_node[\"custom_fields\"]\n            frontend_node_template = frontend_node[\"template\"]\n            _ = process_prompt_template(\n                template=prompt_template,\n                name=\"template\",\n                custom_fields=custom_fields,\n                frontend_node_template=frontend_node_template,\n                is_mustache=is_mustache,\n            )\n        except ValueError as e:\n            # If validation fails, don't add variables but allow component to be created\n            logger.debug(f\"Template validation failed in _update_template: {e}\")\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        use_double_brackets = frontend_node[\"template\"].get(\"use_double_brackets\", {}).get(\"value\", False)\n        is_mustache = use_double_brackets is True\n\n        try:\n            # Validate mustache templates for security\n            if is_mustache:\n                validate_mustache_template(template)\n\n            # Kept it duplicated for backwards compatibility\n            _ = process_prompt_template(\n                template=template,\n                name=\"template\",\n                custom_fields=frontend_node[\"custom_fields\"],\n                frontend_node_template=frontend_node[\"template\"],\n                is_mustache=is_mustache,\n            )\n        except ValueError as e:\n            # If validation fails, don't add variables but allow component to be updated\n            logger.debug(f\"Template validation failed in update_frontend_node: {e}\")\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "context": {
                "advanced": false,
                "display_name": "context",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "platform": {
                "advanced": false,
                "display_name": "platform",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "platform",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "prompt",
                "value": "You are generating ad copy variations for professionals who need high-converting advertising content. Your output must be precise, platform-compliant, and strategically crafted to maximize engagement and conversions.\n\nKeep the language direct and results-focused, avoiding hyperbole or unnecessary embellishment. Do not use linguistic patterns that would indicate AI-generated content, including excessive use of em-dashes, passive voice, or overly formal transitions.\n\n## Platform specifications\nUse the web_search tool to research current specifications for {platform}. Your research must include:\n- Character limits for headlines, descriptions, and body text\n- Required and optional ad components\n- Platform-specific best practices and recent updates\n- Format requirements and technical constraints\n- Current advertising guidelines and policies\n\nUse the current_date tool to ensure your search returns only results from the last 6 months, guaranteeing up-to-date platform specifications.\n\n## Context and requirements\n{context}\n\n## Your task\nGenerate ad copy variations that align with the specifications above. Each variation should:\n1. Comply with all platform character limits and format requirements\n2. Address the target audience's needs and pain points directly\n3. Include a clear, compelling call-to-action\n4. Differentiate through varied strategic angles (benefit-focused, urgency-driven, social proof, problem-solution, exclusivity)\n5. Maintain consistency with the specified tone and brand voice\n\n## Output format\nFor each variation, provide:\n- **Headline**: [within platform character limit]\n- **Description/Body**: [within platform character limit]\n- **Call-to-Action**: [clear and action-oriented]\n- **Strategic Angle**: [which approach this variation uses]"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "use_double_brackets": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Double Brackets",
                "dynamic": false,
                "info": "Use {{variable}} syntax instead of {variable}.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_double_brackets",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-NuOku",
        "measured": {
          "height": 449,
          "width": 320
        },
        "position": {
          "x": 1650.4263953997179,
          "y": 7.959928096296274
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UnifiedWebSearch-TIllK",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Search the web, news, or RSS feeds.",
            "display_name": "Web Search",
            "documentation": "https://docs.langflow.org/web-search",
            "edited": false,
            "field_order": [
              "search_mode",
              "query",
              "hl",
              "gl",
              "ceid",
              "topic",
              "location",
              "timeout"
            ],
            "frozen": false,
            "icon": "search",
            "last_updated": "2026-01-27T02:07:10.760Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "cbeeaef8889a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  },
                  {
                    "name": "requests",
                    "version": "2.32.5"
                  },
                  {
                    "name": "bs4",
                    "version": "4.12.3"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data_source.web_search.WebSearchComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "ceid": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Country:Language (ceid)",
                "dynamic": false,
                "info": "e.g. US:en, FR:fr. Default: US:en.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ceid",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "US:en"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Unified Web Search Component.\n\nThis component consolidates Web Search, News Search, and RSS Reader into a single\ncomponent with tabs for different search modes.\n\"\"\"\n\nimport re\nfrom typing import Any\nfrom urllib.parse import parse_qs, quote_plus, unquote, urlparse\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom lfx.custom import Component\nfrom lfx.io import IntInput, MessageTextInput, Output, TabInput\nfrom lfx.schema import DataFrame\nfrom lfx.utils.request_utils import get_user_agent\n\n\nclass WebSearchComponent(Component):\n    display_name = \"Web Search\"\n    description = \"Search the web, news, or RSS feeds.\"\n    documentation: str = \"https://docs.langflow.org/web-search\"\n    icon = \"search\"\n    name = \"UnifiedWebSearch\"\n\n    inputs = [\n        TabInput(\n            name=\"search_mode\",\n            display_name=\"Search Mode\",\n            options=[\"Web\", \"News\", \"RSS\"],\n            info=\"Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)\",\n            value=\"Web\",\n            real_time_refresh=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Search keywords for news articles.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"hl\",\n            display_name=\"Language (hl)\",\n            info=\"Language code, e.g. en-US, fr, de. Default: en-US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"gl\",\n            display_name=\"Country (gl)\",\n            info=\"Country code, e.g. US, FR, DE. Default: US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"ceid\",\n            display_name=\"Country:Language (ceid)\",\n            info=\"e.g. US:en, FR:fr. Default: US:en.\",\n            tool_mode=False,\n            value=\"US:en\",\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"topic\",\n            display_name=\"Topic\",\n            info=\"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"location\",\n            display_name=\"Location (Geo)\",\n            info=\"City, state, or country for location-based news. Leave blank for keyword search.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=5,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"results\", display_name=\"Results\", method=\"perform_search\")]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        \"\"\"Update input visibility based on search mode.\"\"\"\n        if field_name == \"search_mode\":\n            # Show/hide inputs based on search mode\n            is_news = field_value == \"News\"\n            is_rss = field_value == \"RSS\"\n\n            # Update query field info based on mode\n            if is_rss:\n                build_config[\"query\"][\"info\"] = \"RSS feed URL to parse\"\n                build_config[\"query\"][\"display_name\"] = \"RSS Feed URL\"\n            elif is_news:\n                build_config[\"query\"][\"info\"] = \"Search keywords for news articles.\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n            else:  # Web\n                build_config[\"query\"][\"info\"] = \"Keywords to search for\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n\n            # Keep news-specific fields as advanced (matching original News Search component)\n            # They remain advanced=True in all modes, just like in the original component\n\n        return build_config\n\n    def validate_url(self, string: str) -> bool:\n        \"\"\"Validate URL format.\"\"\"\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensure URL has proper protocol.\"\"\"\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n        return url\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Sanitize search query.\"\"\"\n        return re.sub(r'[<>\"\\']', \"\", query.strip())\n\n    def clean_html(self, html_string: str) -> str:\n        \"\"\"Remove HTML tags from text.\"\"\"\n        return BeautifulSoup(html_string, \"html.parser\").get_text(separator=\" \", strip=True)\n\n    def perform_web_search(self) -> DataFrame:\n        \"\"\"Perform DuckDuckGo web search.\"\"\"\n        query = self._sanitize_query(self.query)\n        if not query:\n            msg = \"Empty search query\"\n            raise ValueError(msg)\n\n        headers = {\"User-Agent\": get_user_agent()}\n        params = {\"q\": query, \"kl\": \"us-en\"}\n        url = \"https://html.duckduckgo.com/html/\"\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            self.status = f\"Failed request: {e!s}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": str(e), \"content\": \"\"}]))\n\n        if not response.text or \"text/html\" not in response.headers.get(\"content-type\", \"\").lower():\n            self.status = \"No results found\"\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": \"No results found\", \"content\": \"\"}])\n            )\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        results = []\n\n        for result in soup.select(\"div.result\"):\n            title_tag = result.select_one(\"a.result__a\")\n            snippet_tag = result.select_one(\"a.result__snippet\")\n            if title_tag:\n                raw_link = title_tag.get(\"href\", \"\")\n                parsed = urlparse(raw_link)\n                uddg = parse_qs(parsed.query).get(\"uddg\", [\"\"])[0]\n                decoded_link = unquote(uddg) if uddg else raw_link\n\n                try:\n                    final_url = self.ensure_url(decoded_link)\n                    page = requests.get(final_url, headers=headers, timeout=self.timeout)\n                    page.raise_for_status()\n                    content = BeautifulSoup(page.text, \"lxml\").get_text(separator=\" \", strip=True)\n                except requests.RequestException as e:\n                    final_url = decoded_link\n                    content = f\"(Failed to fetch: {e!s}\"\n\n                results.append(\n                    {\n                        \"title\": title_tag.get_text(strip=True),\n                        \"link\": final_url,\n                        \"snippet\": snippet_tag.get_text(strip=True) if snippet_tag else \"\",\n                        \"content\": content,\n                    }\n                )\n\n        return DataFrame(pd.DataFrame(results))\n\n    def perform_news_search(self) -> DataFrame:\n        \"\"\"Perform Google News search.\"\"\"\n        query = getattr(self, \"query\", \"\")\n        hl = getattr(self, \"hl\", \"en-US\") or \"en-US\"\n        gl = getattr(self, \"gl\", \"US\") or \"US\"\n        topic = getattr(self, \"topic\", None)\n        location = getattr(self, \"location\", None)\n\n        ceid = f\"{gl}:{hl.split('-')[0]}\"\n\n        # Build RSS URL based on parameters\n        if topic:\n            # Topic-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/topic/{quote_plus(topic.upper())}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif location:\n            # Location-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/geo/{quote_plus(location)}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif query:\n            # Keyword search feed\n            base_url = \"https://news.google.com/rss/search?q=\"\n            query_encoded = quote_plus(query)\n            params = f\"&hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = f\"{base_url}{query_encoded}{params}\"\n        else:\n            self.status = \"No search query, topic, or location provided.\"\n            return DataFrame(\n                pd.DataFrame(\n                    [{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No search parameters provided\"}]\n                )\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except requests.RequestException as e:\n            self.status = f\"Failed to fetch news: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        if not items:\n            self.status = \"No news articles found.\"\n            return DataFrame(pd.DataFrame([{\"title\": \"No articles found\", \"link\": \"\", \"published\": \"\", \"summary\": \"\"}]))\n\n        articles = []\n        for item in items:\n            try:\n                title = self.clean_html(item.title.text if item.title else \"\")\n                link = item.link.text if item.link else \"\"\n                published = item.pubDate.text if item.pubDate else \"\"\n                summary = self.clean_html(item.description.text if item.description else \"\")\n                articles.append({\"title\": title, \"link\": link, \"published\": published, \"summary\": summary})\n            except (AttributeError, ValueError, TypeError) as e:\n                self.log(f\"Error parsing article: {e!s}\")\n                continue\n\n        return DataFrame(pd.DataFrame(articles))\n\n    def perform_rss_read(self) -> DataFrame:\n        \"\"\"Read RSS feed.\"\"\"\n        rss_url = getattr(self, \"query\", \"\")\n        if not rss_url:\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No RSS URL provided\"}])\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            if not response.content.strip():\n                msg = \"Empty response received\"\n                raise ValueError(msg)\n\n            # Validate XML\n            try:\n                BeautifulSoup(response.content, \"xml\")\n            except Exception as e:\n                msg = f\"Invalid XML response: {e}\"\n                raise ValueError(msg) from e\n\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except (requests.RequestException, ValueError) as e:\n            self.status = f\"Failed to fetch RSS: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        articles = [\n            {\n                \"title\": item.title.text if item.title else \"\",\n                \"link\": item.link.text if item.link else \"\",\n                \"published\": item.pubDate.text if item.pubDate else \"\",\n                \"summary\": item.description.text if item.description else \"\",\n            }\n            for item in items\n        ]\n\n        # Ensure DataFrame has correct columns even if empty\n        df_articles = pd.DataFrame(articles, columns=[\"title\", \"link\", \"published\", \"summary\"])\n        self.log(f\"Fetched {len(df_articles)} articles.\")\n        return DataFrame(df_articles)\n\n    def perform_search(self) -> DataFrame:\n        \"\"\"Main search method that routes to appropriate search function based on mode.\"\"\"\n        search_mode = getattr(self, \"search_mode\", \"Web\")\n\n        if search_mode == \"Web\":\n            return self.perform_web_search()\n        if search_mode == \"News\":\n            return self.perform_news_search()\n        if search_mode == \"RSS\":\n            return self.perform_rss_read()\n        # Fallback to web search\n        return self.perform_web_search()\n"
              },
              "gl": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Country (gl)",
                "dynamic": false,
                "info": "Country code, e.g. US, FR, DE. Default: US.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "gl",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "hl": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Language (hl)",
                "dynamic": false,
                "info": "Language code, e.g. en-US, fr, de. Default: en-US.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "hl",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "location": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Location (Geo)",
                "dynamic": false,
                "info": "City, state, or country for location-based news. Leave blank for keyword search.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "location",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Search keywords for news articles.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "search_mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Search Mode",
                "dynamic": false,
                "info": "Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)",
                "name": "search_mode",
                "options": [
                  "Web",
                  "News",
                  "RSS"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "Web"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the request in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 5
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "query": {
                        "description": "Search keywords for news articles.",
                        "title": "Query",
                        "type": "string"
                      },
                      "search_mode": {
                        "default": "Web",
                        "description": "Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)",
                        "enum": [
                          "Web",
                          "News",
                          "RSS"
                        ],
                        "title": "Search Mode",
                        "type": "string"
                      }
                    },
                    "description": "Search the web, news, or RSS feeds.",
                    "display_description": "Search the web, news, or RSS feeds.",
                    "display_name": "perform_search",
                    "name": "perform_search",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "perform_search"
                    ]
                  }
                ]
              },
              "topic": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Topic",
                "dynamic": false,
                "info": "One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "topic",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "UnifiedWebSearch"
        },
        "dragging": false,
        "id": "UnifiedWebSearch-TIllK",
        "measured": {
          "height": 202,
          "width": 320
        },
        "position": {
          "x": 1632.8835760049194,
          "y": -501.4749275213614
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CurrentDate-zvJtP",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Returns the current date and time in the selected timezone.",
            "display_name": "Current Date",
            "documentation": "https://docs.langflow.org/current-date",
            "edited": false,
            "field_order": [
              "timezone"
            ],
            "frozen": false,
            "icon": "clock",
            "last_updated": "2026-01-27T02:07:33.160Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "8311e820e80c",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.utilities.current_date.CurrentDateComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "f791254b-1059-4001-8060-de34613e87df"
              },
              "_frontend_node_folder_id": {
                "value": "a265ce36-7e1f-43cb-9964-16a87b09def2"
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from datetime import datetime\nfrom zoneinfo import ZoneInfo, available_timezones\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.message import Message\n\n\nclass CurrentDateComponent(Component):\n    display_name = \"Current Date\"\n    description = \"Returns the current date and time in the selected timezone.\"\n    documentation: str = \"https://docs.langflow.org/current-date\"\n    icon = \"clock\"\n    name = \"CurrentDate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"timezone\",\n            display_name=\"Timezone\",\n            options=sorted(tz for tz in available_timezones() if tz != \"localtime\"),\n            value=\"UTC\",\n            info=\"Select the timezone for the current date and time.\",\n            tool_mode=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\n    ]\n\n    def get_current_date(self) -> Message:\n        try:\n            tz = ZoneInfo(self.timezone)\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\n            self.status = result\n            return Message(text=result)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error getting current date\", exc_info=True)\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return Message(text=error_message)\n"
              },
              "is_refresh": false,
              "timezone": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Timezone",
                "dynamic": false,
                "external_options": {},
                "info": "Select the timezone for the current date and time.",
                "name": "timezone",
                "options": [
                  "Africa/Abidjan",
                  "Africa/Accra",
                  "Africa/Addis_Ababa",
                  "Africa/Algiers",
                  "Africa/Asmara",
                  "Africa/Asmera",
                  "Africa/Bamako",
                  "Africa/Bangui",
                  "Africa/Banjul",
                  "Africa/Bissau",
                  "Africa/Blantyre",
                  "Africa/Brazzaville",
                  "Africa/Bujumbura",
                  "Africa/Cairo",
                  "Africa/Casablanca",
                  "Africa/Ceuta",
                  "Africa/Conakry",
                  "Africa/Dakar",
                  "Africa/Dar_es_Salaam",
                  "Africa/Djibouti",
                  "Africa/Douala",
                  "Africa/El_Aaiun",
                  "Africa/Freetown",
                  "Africa/Gaborone",
                  "Africa/Harare",
                  "Africa/Johannesburg",
                  "Africa/Juba",
                  "Africa/Kampala",
                  "Africa/Khartoum",
                  "Africa/Kigali",
                  "Africa/Kinshasa",
                  "Africa/Lagos",
                  "Africa/Libreville",
                  "Africa/Lome",
                  "Africa/Luanda",
                  "Africa/Lubumbashi",
                  "Africa/Lusaka",
                  "Africa/Malabo",
                  "Africa/Maputo",
                  "Africa/Maseru",
                  "Africa/Mbabane",
                  "Africa/Mogadishu",
                  "Africa/Monrovia",
                  "Africa/Nairobi",
                  "Africa/Ndjamena",
                  "Africa/Niamey",
                  "Africa/Nouakchott",
                  "Africa/Ouagadougou",
                  "Africa/Porto-Novo",
                  "Africa/Sao_Tome",
                  "Africa/Timbuktu",
                  "Africa/Tripoli",
                  "Africa/Tunis",
                  "Africa/Windhoek",
                  "America/Adak",
                  "America/Anchorage",
                  "America/Anguilla",
                  "America/Antigua",
                  "America/Araguaina",
                  "America/Argentina/Buenos_Aires",
                  "America/Argentina/Catamarca",
                  "America/Argentina/ComodRivadavia",
                  "America/Argentina/Cordoba",
                  "America/Argentina/Jujuy",
                  "America/Argentina/La_Rioja",
                  "America/Argentina/Mendoza",
                  "America/Argentina/Rio_Gallegos",
                  "America/Argentina/Salta",
                  "America/Argentina/San_Juan",
                  "America/Argentina/San_Luis",
                  "America/Argentina/Tucuman",
                  "America/Argentina/Ushuaia",
                  "America/Aruba",
                  "America/Asuncion",
                  "America/Atikokan",
                  "America/Atka",
                  "America/Bahia",
                  "America/Bahia_Banderas",
                  "America/Barbados",
                  "America/Belem",
                  "America/Belize",
                  "America/Blanc-Sablon",
                  "America/Boa_Vista",
                  "America/Bogota",
                  "America/Boise",
                  "America/Buenos_Aires",
                  "America/Cambridge_Bay",
                  "America/Campo_Grande",
                  "America/Cancun",
                  "America/Caracas",
                  "America/Catamarca",
                  "America/Cayenne",
                  "America/Cayman",
                  "America/Chicago",
                  "America/Chihuahua",
                  "America/Ciudad_Juarez",
                  "America/Coral_Harbour",
                  "America/Cordoba",
                  "America/Costa_Rica",
                  "America/Coyhaique",
                  "America/Creston",
                  "America/Cuiaba",
                  "America/Curacao",
                  "America/Danmarkshavn",
                  "America/Dawson",
                  "America/Dawson_Creek",
                  "America/Denver",
                  "America/Detroit",
                  "America/Dominica",
                  "America/Edmonton",
                  "America/Eirunepe",
                  "America/El_Salvador",
                  "America/Ensenada",
                  "America/Fort_Nelson",
                  "America/Fort_Wayne",
                  "America/Fortaleza",
                  "America/Glace_Bay",
                  "America/Godthab",
                  "America/Goose_Bay",
                  "America/Grand_Turk",
                  "America/Grenada",
                  "America/Guadeloupe",
                  "America/Guatemala",
                  "America/Guayaquil",
                  "America/Guyana",
                  "America/Halifax",
                  "America/Havana",
                  "America/Hermosillo",
                  "America/Indiana/Indianapolis",
                  "America/Indiana/Knox",
                  "America/Indiana/Marengo",
                  "America/Indiana/Petersburg",
                  "America/Indiana/Tell_City",
                  "America/Indiana/Vevay",
                  "America/Indiana/Vincennes",
                  "America/Indiana/Winamac",
                  "America/Indianapolis",
                  "America/Inuvik",
                  "America/Iqaluit",
                  "America/Jamaica",
                  "America/Jujuy",
                  "America/Juneau",
                  "America/Kentucky/Louisville",
                  "America/Kentucky/Monticello",
                  "America/Knox_IN",
                  "America/Kralendijk",
                  "America/La_Paz",
                  "America/Lima",
                  "America/Los_Angeles",
                  "America/Louisville",
                  "America/Lower_Princes",
                  "America/Maceio",
                  "America/Managua",
                  "America/Manaus",
                  "America/Marigot",
                  "America/Martinique",
                  "America/Matamoros",
                  "America/Mazatlan",
                  "America/Mendoza",
                  "America/Menominee",
                  "America/Merida",
                  "America/Metlakatla",
                  "America/Mexico_City",
                  "America/Miquelon",
                  "America/Moncton",
                  "America/Monterrey",
                  "America/Montevideo",
                  "America/Montreal",
                  "America/Montserrat",
                  "America/Nassau",
                  "America/New_York",
                  "America/Nipigon",
                  "America/Nome",
                  "America/Noronha",
                  "America/North_Dakota/Beulah",
                  "America/North_Dakota/Center",
                  "America/North_Dakota/New_Salem",
                  "America/Nuuk",
                  "America/Ojinaga",
                  "America/Panama",
                  "America/Pangnirtung",
                  "America/Paramaribo",
                  "America/Phoenix",
                  "America/Port-au-Prince",
                  "America/Port_of_Spain",
                  "America/Porto_Acre",
                  "America/Porto_Velho",
                  "America/Puerto_Rico",
                  "America/Punta_Arenas",
                  "America/Rainy_River",
                  "America/Rankin_Inlet",
                  "America/Recife",
                  "America/Regina",
                  "America/Resolute",
                  "America/Rio_Branco",
                  "America/Rosario",
                  "America/Santa_Isabel",
                  "America/Santarem",
                  "America/Santiago",
                  "America/Santo_Domingo",
                  "America/Sao_Paulo",
                  "America/Scoresbysund",
                  "America/Shiprock",
                  "America/Sitka",
                  "America/St_Barthelemy",
                  "America/St_Johns",
                  "America/St_Kitts",
                  "America/St_Lucia",
                  "America/St_Thomas",
                  "America/St_Vincent",
                  "America/Swift_Current",
                  "America/Tegucigalpa",
                  "America/Thule",
                  "America/Thunder_Bay",
                  "America/Tijuana",
                  "America/Toronto",
                  "America/Tortola",
                  "America/Vancouver",
                  "America/Virgin",
                  "America/Whitehorse",
                  "America/Winnipeg",
                  "America/Yakutat",
                  "America/Yellowknife",
                  "Antarctica/Casey",
                  "Antarctica/Davis",
                  "Antarctica/DumontDUrville",
                  "Antarctica/Macquarie",
                  "Antarctica/Mawson",
                  "Antarctica/McMurdo",
                  "Antarctica/Palmer",
                  "Antarctica/Rothera",
                  "Antarctica/South_Pole",
                  "Antarctica/Syowa",
                  "Antarctica/Troll",
                  "Antarctica/Vostok",
                  "Arctic/Longyearbyen",
                  "Asia/Aden",
                  "Asia/Almaty",
                  "Asia/Amman",
                  "Asia/Anadyr",
                  "Asia/Aqtau",
                  "Asia/Aqtobe",
                  "Asia/Ashgabat",
                  "Asia/Ashkhabad",
                  "Asia/Atyrau",
                  "Asia/Baghdad",
                  "Asia/Bahrain",
                  "Asia/Baku",
                  "Asia/Bangkok",
                  "Asia/Barnaul",
                  "Asia/Beirut",
                  "Asia/Bishkek",
                  "Asia/Brunei",
                  "Asia/Calcutta",
                  "Asia/Chita",
                  "Asia/Choibalsan",
                  "Asia/Chongqing",
                  "Asia/Chungking",
                  "Asia/Colombo",
                  "Asia/Dacca",
                  "Asia/Damascus",
                  "Asia/Dhaka",
                  "Asia/Dili",
                  "Asia/Dubai",
                  "Asia/Dushanbe",
                  "Asia/Famagusta",
                  "Asia/Gaza",
                  "Asia/Harbin",
                  "Asia/Hebron",
                  "Asia/Ho_Chi_Minh",
                  "Asia/Hong_Kong",
                  "Asia/Hovd",
                  "Asia/Irkutsk",
                  "Asia/Istanbul",
                  "Asia/Jakarta",
                  "Asia/Jayapura",
                  "Asia/Jerusalem",
                  "Asia/Kabul",
                  "Asia/Kamchatka",
                  "Asia/Karachi",
                  "Asia/Kashgar",
                  "Asia/Kathmandu",
                  "Asia/Katmandu",
                  "Asia/Khandyga",
                  "Asia/Kolkata",
                  "Asia/Krasnoyarsk",
                  "Asia/Kuala_Lumpur",
                  "Asia/Kuching",
                  "Asia/Kuwait",
                  "Asia/Macao",
                  "Asia/Macau",
                  "Asia/Magadan",
                  "Asia/Makassar",
                  "Asia/Manila",
                  "Asia/Muscat",
                  "Asia/Nicosia",
                  "Asia/Novokuznetsk",
                  "Asia/Novosibirsk",
                  "Asia/Omsk",
                  "Asia/Oral",
                  "Asia/Phnom_Penh",
                  "Asia/Pontianak",
                  "Asia/Pyongyang",
                  "Asia/Qatar",
                  "Asia/Qostanay",
                  "Asia/Qyzylorda",
                  "Asia/Rangoon",
                  "Asia/Riyadh",
                  "Asia/Saigon",
                  "Asia/Sakhalin",
                  "Asia/Samarkand",
                  "Asia/Seoul",
                  "Asia/Shanghai",
                  "Asia/Singapore",
                  "Asia/Srednekolymsk",
                  "Asia/Taipei",
                  "Asia/Tashkent",
                  "Asia/Tbilisi",
                  "Asia/Tehran",
                  "Asia/Tel_Aviv",
                  "Asia/Thimbu",
                  "Asia/Thimphu",
                  "Asia/Tokyo",
                  "Asia/Tomsk",
                  "Asia/Ujung_Pandang",
                  "Asia/Ulaanbaatar",
                  "Asia/Ulan_Bator",
                  "Asia/Urumqi",
                  "Asia/Ust-Nera",
                  "Asia/Vientiane",
                  "Asia/Vladivostok",
                  "Asia/Yakutsk",
                  "Asia/Yangon",
                  "Asia/Yekaterinburg",
                  "Asia/Yerevan",
                  "Atlantic/Azores",
                  "Atlantic/Bermuda",
                  "Atlantic/Canary",
                  "Atlantic/Cape_Verde",
                  "Atlantic/Faeroe",
                  "Atlantic/Faroe",
                  "Atlantic/Jan_Mayen",
                  "Atlantic/Madeira",
                  "Atlantic/Reykjavik",
                  "Atlantic/South_Georgia",
                  "Atlantic/St_Helena",
                  "Atlantic/Stanley",
                  "Australia/ACT",
                  "Australia/Adelaide",
                  "Australia/Brisbane",
                  "Australia/Broken_Hill",
                  "Australia/Canberra",
                  "Australia/Currie",
                  "Australia/Darwin",
                  "Australia/Eucla",
                  "Australia/Hobart",
                  "Australia/LHI",
                  "Australia/Lindeman",
                  "Australia/Lord_Howe",
                  "Australia/Melbourne",
                  "Australia/NSW",
                  "Australia/North",
                  "Australia/Perth",
                  "Australia/Queensland",
                  "Australia/South",
                  "Australia/Sydney",
                  "Australia/Tasmania",
                  "Australia/Victoria",
                  "Australia/West",
                  "Australia/Yancowinna",
                  "Brazil/Acre",
                  "Brazil/DeNoronha",
                  "Brazil/East",
                  "Brazil/West",
                  "CET",
                  "CST6CDT",
                  "Canada/Atlantic",
                  "Canada/Central",
                  "Canada/Eastern",
                  "Canada/Mountain",
                  "Canada/Newfoundland",
                  "Canada/Pacific",
                  "Canada/Saskatchewan",
                  "Canada/Yukon",
                  "Chile/Continental",
                  "Chile/EasterIsland",
                  "Cuba",
                  "EET",
                  "EST",
                  "EST5EDT",
                  "Egypt",
                  "Eire",
                  "Etc/GMT",
                  "Etc/GMT+0",
                  "Etc/GMT+1",
                  "Etc/GMT+10",
                  "Etc/GMT+11",
                  "Etc/GMT+12",
                  "Etc/GMT+2",
                  "Etc/GMT+3",
                  "Etc/GMT+4",
                  "Etc/GMT+5",
                  "Etc/GMT+6",
                  "Etc/GMT+7",
                  "Etc/GMT+8",
                  "Etc/GMT+9",
                  "Etc/GMT-0",
                  "Etc/GMT-1",
                  "Etc/GMT-10",
                  "Etc/GMT-11",
                  "Etc/GMT-12",
                  "Etc/GMT-13",
                  "Etc/GMT-14",
                  "Etc/GMT-2",
                  "Etc/GMT-3",
                  "Etc/GMT-4",
                  "Etc/GMT-5",
                  "Etc/GMT-6",
                  "Etc/GMT-7",
                  "Etc/GMT-8",
                  "Etc/GMT-9",
                  "Etc/GMT0",
                  "Etc/Greenwich",
                  "Etc/UCT",
                  "Etc/UTC",
                  "Etc/Universal",
                  "Etc/Zulu",
                  "Europe/Amsterdam",
                  "Europe/Andorra",
                  "Europe/Astrakhan",
                  "Europe/Athens",
                  "Europe/Belfast",
                  "Europe/Belgrade",
                  "Europe/Berlin",
                  "Europe/Bratislava",
                  "Europe/Brussels",
                  "Europe/Bucharest",
                  "Europe/Budapest",
                  "Europe/Busingen",
                  "Europe/Chisinau",
                  "Europe/Copenhagen",
                  "Europe/Dublin",
                  "Europe/Gibraltar",
                  "Europe/Guernsey",
                  "Europe/Helsinki",
                  "Europe/Isle_of_Man",
                  "Europe/Istanbul",
                  "Europe/Jersey",
                  "Europe/Kaliningrad",
                  "Europe/Kiev",
                  "Europe/Kirov",
                  "Europe/Kyiv",
                  "Europe/Lisbon",
                  "Europe/Ljubljana",
                  "Europe/London",
                  "Europe/Luxembourg",
                  "Europe/Madrid",
                  "Europe/Malta",
                  "Europe/Mariehamn",
                  "Europe/Minsk",
                  "Europe/Monaco",
                  "Europe/Moscow",
                  "Europe/Nicosia",
                  "Europe/Oslo",
                  "Europe/Paris",
                  "Europe/Podgorica",
                  "Europe/Prague",
                  "Europe/Riga",
                  "Europe/Rome",
                  "Europe/Samara",
                  "Europe/San_Marino",
                  "Europe/Sarajevo",
                  "Europe/Saratov",
                  "Europe/Simferopol",
                  "Europe/Skopje",
                  "Europe/Sofia",
                  "Europe/Stockholm",
                  "Europe/Tallinn",
                  "Europe/Tirane",
                  "Europe/Tiraspol",
                  "Europe/Ulyanovsk",
                  "Europe/Uzhgorod",
                  "Europe/Vaduz",
                  "Europe/Vatican",
                  "Europe/Vienna",
                  "Europe/Vilnius",
                  "Europe/Volgograd",
                  "Europe/Warsaw",
                  "Europe/Zagreb",
                  "Europe/Zaporozhye",
                  "Europe/Zurich",
                  "Factory",
                  "GB",
                  "GB-Eire",
                  "GMT",
                  "GMT+0",
                  "GMT-0",
                  "GMT0",
                  "Greenwich",
                  "HST",
                  "Hongkong",
                  "Iceland",
                  "Indian/Antananarivo",
                  "Indian/Chagos",
                  "Indian/Christmas",
                  "Indian/Cocos",
                  "Indian/Comoro",
                  "Indian/Kerguelen",
                  "Indian/Mahe",
                  "Indian/Maldives",
                  "Indian/Mauritius",
                  "Indian/Mayotte",
                  "Indian/Reunion",
                  "Iran",
                  "Israel",
                  "Jamaica",
                  "Japan",
                  "Kwajalein",
                  "Libya",
                  "MET",
                  "MST",
                  "MST7MDT",
                  "Mexico/BajaNorte",
                  "Mexico/BajaSur",
                  "Mexico/General",
                  "NZ",
                  "NZ-CHAT",
                  "Navajo",
                  "PRC",
                  "PST8PDT",
                  "Pacific/Apia",
                  "Pacific/Auckland",
                  "Pacific/Bougainville",
                  "Pacific/Chatham",
                  "Pacific/Chuuk",
                  "Pacific/Easter",
                  "Pacific/Efate",
                  "Pacific/Enderbury",
                  "Pacific/Fakaofo",
                  "Pacific/Fiji",
                  "Pacific/Funafuti",
                  "Pacific/Galapagos",
                  "Pacific/Gambier",
                  "Pacific/Guadalcanal",
                  "Pacific/Guam",
                  "Pacific/Honolulu",
                  "Pacific/Johnston",
                  "Pacific/Kanton",
                  "Pacific/Kiritimati",
                  "Pacific/Kosrae",
                  "Pacific/Kwajalein",
                  "Pacific/Majuro",
                  "Pacific/Marquesas",
                  "Pacific/Midway",
                  "Pacific/Nauru",
                  "Pacific/Niue",
                  "Pacific/Norfolk",
                  "Pacific/Noumea",
                  "Pacific/Pago_Pago",
                  "Pacific/Palau",
                  "Pacific/Pitcairn",
                  "Pacific/Pohnpei",
                  "Pacific/Ponape",
                  "Pacific/Port_Moresby",
                  "Pacific/Rarotonga",
                  "Pacific/Saipan",
                  "Pacific/Samoa",
                  "Pacific/Tahiti",
                  "Pacific/Tarawa",
                  "Pacific/Tongatapu",
                  "Pacific/Truk",
                  "Pacific/Wake",
                  "Pacific/Wallis",
                  "Pacific/Yap",
                  "Poland",
                  "Portugal",
                  "ROC",
                  "ROK",
                  "Singapore",
                  "Turkey",
                  "UCT",
                  "US/Alaska",
                  "US/Aleutian",
                  "US/Arizona",
                  "US/Central",
                  "US/East-Indiana",
                  "US/Eastern",
                  "US/Hawaii",
                  "US/Indiana-Starke",
                  "US/Michigan",
                  "US/Mountain",
                  "US/Pacific",
                  "US/Samoa",
                  "UTC",
                  "Universal",
                  "W-SU",
                  "WET",
                  "Zulu"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "UTC"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "timezone": {
                        "default": "UTC",
                        "description": "Select the timezone for the current date and time.",
                        "enum": [
                          "Africa/Abidjan",
                          "Africa/Accra",
                          "Africa/Addis_Ababa",
                          "Africa/Algiers",
                          "Africa/Asmara",
                          "Africa/Asmera",
                          "Africa/Bamako",
                          "Africa/Bangui",
                          "Africa/Banjul",
                          "Africa/Bissau",
                          "Africa/Blantyre",
                          "Africa/Brazzaville",
                          "Africa/Bujumbura",
                          "Africa/Cairo",
                          "Africa/Casablanca",
                          "Africa/Ceuta",
                          "Africa/Conakry",
                          "Africa/Dakar",
                          "Africa/Dar_es_Salaam",
                          "Africa/Djibouti",
                          "Africa/Douala",
                          "Africa/El_Aaiun",
                          "Africa/Freetown",
                          "Africa/Gaborone",
                          "Africa/Harare",
                          "Africa/Johannesburg",
                          "Africa/Juba",
                          "Africa/Kampala",
                          "Africa/Khartoum",
                          "Africa/Kigali",
                          "Africa/Kinshasa",
                          "Africa/Lagos",
                          "Africa/Libreville",
                          "Africa/Lome",
                          "Africa/Luanda",
                          "Africa/Lubumbashi",
                          "Africa/Lusaka",
                          "Africa/Malabo",
                          "Africa/Maputo",
                          "Africa/Maseru",
                          "Africa/Mbabane",
                          "Africa/Mogadishu",
                          "Africa/Monrovia",
                          "Africa/Nairobi",
                          "Africa/Ndjamena",
                          "Africa/Niamey",
                          "Africa/Nouakchott",
                          "Africa/Ouagadougou",
                          "Africa/Porto-Novo",
                          "Africa/Sao_Tome",
                          "Africa/Timbuktu",
                          "Africa/Tripoli",
                          "Africa/Tunis",
                          "Africa/Windhoek",
                          "America/Adak",
                          "America/Anchorage",
                          "America/Anguilla",
                          "America/Antigua",
                          "America/Araguaina",
                          "America/Argentina/Buenos_Aires",
                          "America/Argentina/Catamarca",
                          "America/Argentina/ComodRivadavia",
                          "America/Argentina/Cordoba",
                          "America/Argentina/Jujuy",
                          "America/Argentina/La_Rioja",
                          "America/Argentina/Mendoza",
                          "America/Argentina/Rio_Gallegos",
                          "America/Argentina/Salta",
                          "America/Argentina/San_Juan",
                          "America/Argentina/San_Luis",
                          "America/Argentina/Tucuman",
                          "America/Argentina/Ushuaia",
                          "America/Aruba",
                          "America/Asuncion",
                          "America/Atikokan",
                          "America/Atka",
                          "America/Bahia",
                          "America/Bahia_Banderas",
                          "America/Barbados",
                          "America/Belem",
                          "America/Belize",
                          "America/Blanc-Sablon",
                          "America/Boa_Vista",
                          "America/Bogota",
                          "America/Boise",
                          "America/Buenos_Aires",
                          "America/Cambridge_Bay",
                          "America/Campo_Grande",
                          "America/Cancun",
                          "America/Caracas",
                          "America/Catamarca",
                          "America/Cayenne",
                          "America/Cayman",
                          "America/Chicago",
                          "America/Chihuahua",
                          "America/Ciudad_Juarez",
                          "America/Coral_Harbour",
                          "America/Cordoba",
                          "America/Costa_Rica",
                          "America/Coyhaique",
                          "America/Creston",
                          "America/Cuiaba",
                          "America/Curacao",
                          "America/Danmarkshavn",
                          "America/Dawson",
                          "America/Dawson_Creek",
                          "America/Denver",
                          "America/Detroit",
                          "America/Dominica",
                          "America/Edmonton",
                          "America/Eirunepe",
                          "America/El_Salvador",
                          "America/Ensenada",
                          "America/Fort_Nelson",
                          "America/Fort_Wayne",
                          "America/Fortaleza",
                          "America/Glace_Bay",
                          "America/Godthab",
                          "America/Goose_Bay",
                          "America/Grand_Turk",
                          "America/Grenada",
                          "America/Guadeloupe",
                          "America/Guatemala",
                          "America/Guayaquil",
                          "America/Guyana",
                          "America/Halifax",
                          "America/Havana",
                          "America/Hermosillo",
                          "America/Indiana/Indianapolis",
                          "America/Indiana/Knox",
                          "America/Indiana/Marengo",
                          "America/Indiana/Petersburg",
                          "America/Indiana/Tell_City",
                          "America/Indiana/Vevay",
                          "America/Indiana/Vincennes",
                          "America/Indiana/Winamac",
                          "America/Indianapolis",
                          "America/Inuvik",
                          "America/Iqaluit",
                          "America/Jamaica",
                          "America/Jujuy",
                          "America/Juneau",
                          "America/Kentucky/Louisville",
                          "America/Kentucky/Monticello",
                          "America/Knox_IN",
                          "America/Kralendijk",
                          "America/La_Paz",
                          "America/Lima",
                          "America/Los_Angeles",
                          "America/Louisville",
                          "America/Lower_Princes",
                          "America/Maceio",
                          "America/Managua",
                          "America/Manaus",
                          "America/Marigot",
                          "America/Martinique",
                          "America/Matamoros",
                          "America/Mazatlan",
                          "America/Mendoza",
                          "America/Menominee",
                          "America/Merida",
                          "America/Metlakatla",
                          "America/Mexico_City",
                          "America/Miquelon",
                          "America/Moncton",
                          "America/Monterrey",
                          "America/Montevideo",
                          "America/Montreal",
                          "America/Montserrat",
                          "America/Nassau",
                          "America/New_York",
                          "America/Nipigon",
                          "America/Nome",
                          "America/Noronha",
                          "America/North_Dakota/Beulah",
                          "America/North_Dakota/Center",
                          "America/North_Dakota/New_Salem",
                          "America/Nuuk",
                          "America/Ojinaga",
                          "America/Panama",
                          "America/Pangnirtung",
                          "America/Paramaribo",
                          "America/Phoenix",
                          "America/Port-au-Prince",
                          "America/Port_of_Spain",
                          "America/Porto_Acre",
                          "America/Porto_Velho",
                          "America/Puerto_Rico",
                          "America/Punta_Arenas",
                          "America/Rainy_River",
                          "America/Rankin_Inlet",
                          "America/Recife",
                          "America/Regina",
                          "America/Resolute",
                          "America/Rio_Branco",
                          "America/Rosario",
                          "America/Santa_Isabel",
                          "America/Santarem",
                          "America/Santiago",
                          "America/Santo_Domingo",
                          "America/Sao_Paulo",
                          "America/Scoresbysund",
                          "America/Shiprock",
                          "America/Sitka",
                          "America/St_Barthelemy",
                          "America/St_Johns",
                          "America/St_Kitts",
                          "America/St_Lucia",
                          "America/St_Thomas",
                          "America/St_Vincent",
                          "America/Swift_Current",
                          "America/Tegucigalpa",
                          "America/Thule",
                          "America/Thunder_Bay",
                          "America/Tijuana",
                          "America/Toronto",
                          "America/Tortola",
                          "America/Vancouver",
                          "America/Virgin",
                          "America/Whitehorse",
                          "America/Winnipeg",
                          "America/Yakutat",
                          "America/Yellowknife",
                          "Antarctica/Casey",
                          "Antarctica/Davis",
                          "Antarctica/DumontDUrville",
                          "Antarctica/Macquarie",
                          "Antarctica/Mawson",
                          "Antarctica/McMurdo",
                          "Antarctica/Palmer",
                          "Antarctica/Rothera",
                          "Antarctica/South_Pole",
                          "Antarctica/Syowa",
                          "Antarctica/Troll",
                          "Antarctica/Vostok",
                          "Arctic/Longyearbyen",
                          "Asia/Aden",
                          "Asia/Almaty",
                          "Asia/Amman",
                          "Asia/Anadyr",
                          "Asia/Aqtau",
                          "Asia/Aqtobe",
                          "Asia/Ashgabat",
                          "Asia/Ashkhabad",
                          "Asia/Atyrau",
                          "Asia/Baghdad",
                          "Asia/Bahrain",
                          "Asia/Baku",
                          "Asia/Bangkok",
                          "Asia/Barnaul",
                          "Asia/Beirut",
                          "Asia/Bishkek",
                          "Asia/Brunei",
                          "Asia/Calcutta",
                          "Asia/Chita",
                          "Asia/Choibalsan",
                          "Asia/Chongqing",
                          "Asia/Chungking",
                          "Asia/Colombo",
                          "Asia/Dacca",
                          "Asia/Damascus",
                          "Asia/Dhaka",
                          "Asia/Dili",
                          "Asia/Dubai",
                          "Asia/Dushanbe",
                          "Asia/Famagusta",
                          "Asia/Gaza",
                          "Asia/Harbin",
                          "Asia/Hebron",
                          "Asia/Ho_Chi_Minh",
                          "Asia/Hong_Kong",
                          "Asia/Hovd",
                          "Asia/Irkutsk",
                          "Asia/Istanbul",
                          "Asia/Jakarta",
                          "Asia/Jayapura",
                          "Asia/Jerusalem",
                          "Asia/Kabul",
                          "Asia/Kamchatka",
                          "Asia/Karachi",
                          "Asia/Kashgar",
                          "Asia/Kathmandu",
                          "Asia/Katmandu",
                          "Asia/Khandyga",
                          "Asia/Kolkata",
                          "Asia/Krasnoyarsk",
                          "Asia/Kuala_Lumpur",
                          "Asia/Kuching",
                          "Asia/Kuwait",
                          "Asia/Macao",
                          "Asia/Macau",
                          "Asia/Magadan",
                          "Asia/Makassar",
                          "Asia/Manila",
                          "Asia/Muscat",
                          "Asia/Nicosia",
                          "Asia/Novokuznetsk",
                          "Asia/Novosibirsk",
                          "Asia/Omsk",
                          "Asia/Oral",
                          "Asia/Phnom_Penh",
                          "Asia/Pontianak",
                          "Asia/Pyongyang",
                          "Asia/Qatar",
                          "Asia/Qostanay",
                          "Asia/Qyzylorda",
                          "Asia/Rangoon",
                          "Asia/Riyadh",
                          "Asia/Saigon",
                          "Asia/Sakhalin",
                          "Asia/Samarkand",
                          "Asia/Seoul",
                          "Asia/Shanghai",
                          "Asia/Singapore",
                          "Asia/Srednekolymsk",
                          "Asia/Taipei",
                          "Asia/Tashkent",
                          "Asia/Tbilisi",
                          "Asia/Tehran",
                          "Asia/Tel_Aviv",
                          "Asia/Thimbu",
                          "Asia/Thimphu",
                          "Asia/Tokyo",
                          "Asia/Tomsk",
                          "Asia/Ujung_Pandang",
                          "Asia/Ulaanbaatar",
                          "Asia/Ulan_Bator",
                          "Asia/Urumqi",
                          "Asia/Ust-Nera",
                          "Asia/Vientiane",
                          "Asia/Vladivostok",
                          "Asia/Yakutsk",
                          "Asia/Yangon",
                          "Asia/Yekaterinburg",
                          "Asia/Yerevan",
                          "Atlantic/Azores",
                          "Atlantic/Bermuda",
                          "Atlantic/Canary",
                          "Atlantic/Cape_Verde",
                          "Atlantic/Faeroe",
                          "Atlantic/Faroe",
                          "Atlantic/Jan_Mayen",
                          "Atlantic/Madeira",
                          "Atlantic/Reykjavik",
                          "Atlantic/South_Georgia",
                          "Atlantic/St_Helena",
                          "Atlantic/Stanley",
                          "Australia/ACT",
                          "Australia/Adelaide",
                          "Australia/Brisbane",
                          "Australia/Broken_Hill",
                          "Australia/Canberra",
                          "Australia/Currie",
                          "Australia/Darwin",
                          "Australia/Eucla",
                          "Australia/Hobart",
                          "Australia/LHI",
                          "Australia/Lindeman",
                          "Australia/Lord_Howe",
                          "Australia/Melbourne",
                          "Australia/NSW",
                          "Australia/North",
                          "Australia/Perth",
                          "Australia/Queensland",
                          "Australia/South",
                          "Australia/Sydney",
                          "Australia/Tasmania",
                          "Australia/Victoria",
                          "Australia/West",
                          "Australia/Yancowinna",
                          "Brazil/Acre",
                          "Brazil/DeNoronha",
                          "Brazil/East",
                          "Brazil/West",
                          "CET",
                          "CST6CDT",
                          "Canada/Atlantic",
                          "Canada/Central",
                          "Canada/Eastern",
                          "Canada/Mountain",
                          "Canada/Newfoundland",
                          "Canada/Pacific",
                          "Canada/Saskatchewan",
                          "Canada/Yukon",
                          "Chile/Continental",
                          "Chile/EasterIsland",
                          "Cuba",
                          "EET",
                          "EST",
                          "EST5EDT",
                          "Egypt",
                          "Eire",
                          "Etc/GMT",
                          "Etc/GMT+0",
                          "Etc/GMT+1",
                          "Etc/GMT+10",
                          "Etc/GMT+11",
                          "Etc/GMT+12",
                          "Etc/GMT+2",
                          "Etc/GMT+3",
                          "Etc/GMT+4",
                          "Etc/GMT+5",
                          "Etc/GMT+6",
                          "Etc/GMT+7",
                          "Etc/GMT+8",
                          "Etc/GMT+9",
                          "Etc/GMT-0",
                          "Etc/GMT-1",
                          "Etc/GMT-10",
                          "Etc/GMT-11",
                          "Etc/GMT-12",
                          "Etc/GMT-13",
                          "Etc/GMT-14",
                          "Etc/GMT-2",
                          "Etc/GMT-3",
                          "Etc/GMT-4",
                          "Etc/GMT-5",
                          "Etc/GMT-6",
                          "Etc/GMT-7",
                          "Etc/GMT-8",
                          "Etc/GMT-9",
                          "Etc/GMT0",
                          "Etc/Greenwich",
                          "Etc/UCT",
                          "Etc/UTC",
                          "Etc/Universal",
                          "Etc/Zulu",
                          "Europe/Amsterdam",
                          "Europe/Andorra",
                          "Europe/Astrakhan",
                          "Europe/Athens",
                          "Europe/Belfast",
                          "Europe/Belgrade",
                          "Europe/Berlin",
                          "Europe/Bratislava",
                          "Europe/Brussels",
                          "Europe/Bucharest",
                          "Europe/Budapest",
                          "Europe/Busingen",
                          "Europe/Chisinau",
                          "Europe/Copenhagen",
                          "Europe/Dublin",
                          "Europe/Gibraltar",
                          "Europe/Guernsey",
                          "Europe/Helsinki",
                          "Europe/Isle_of_Man",
                          "Europe/Istanbul",
                          "Europe/Jersey",
                          "Europe/Kaliningrad",
                          "Europe/Kiev",
                          "Europe/Kirov",
                          "Europe/Kyiv",
                          "Europe/Lisbon",
                          "Europe/Ljubljana",
                          "Europe/London",
                          "Europe/Luxembourg",
                          "Europe/Madrid",
                          "Europe/Malta",
                          "Europe/Mariehamn",
                          "Europe/Minsk",
                          "Europe/Monaco",
                          "Europe/Moscow",
                          "Europe/Nicosia",
                          "Europe/Oslo",
                          "Europe/Paris",
                          "Europe/Podgorica",
                          "Europe/Prague",
                          "Europe/Riga",
                          "Europe/Rome",
                          "Europe/Samara",
                          "Europe/San_Marino",
                          "Europe/Sarajevo",
                          "Europe/Saratov",
                          "Europe/Simferopol",
                          "Europe/Skopje",
                          "Europe/Sofia",
                          "Europe/Stockholm",
                          "Europe/Tallinn",
                          "Europe/Tirane",
                          "Europe/Tiraspol",
                          "Europe/Ulyanovsk",
                          "Europe/Uzhgorod",
                          "Europe/Vaduz",
                          "Europe/Vatican",
                          "Europe/Vienna",
                          "Europe/Vilnius",
                          "Europe/Volgograd",
                          "Europe/Warsaw",
                          "Europe/Zagreb",
                          "Europe/Zaporozhye",
                          "Europe/Zurich",
                          "Factory",
                          "GB",
                          "GB-Eire",
                          "GMT",
                          "GMT+0",
                          "GMT-0",
                          "GMT0",
                          "Greenwich",
                          "HST",
                          "Hongkong",
                          "Iceland",
                          "Indian/Antananarivo",
                          "Indian/Chagos",
                          "Indian/Christmas",
                          "Indian/Cocos",
                          "Indian/Comoro",
                          "Indian/Kerguelen",
                          "Indian/Mahe",
                          "Indian/Maldives",
                          "Indian/Mauritius",
                          "Indian/Mayotte",
                          "Indian/Reunion",
                          "Iran",
                          "Israel",
                          "Jamaica",
                          "Japan",
                          "Kwajalein",
                          "Libya",
                          "MET",
                          "MST",
                          "MST7MDT",
                          "Mexico/BajaNorte",
                          "Mexico/BajaSur",
                          "Mexico/General",
                          "NZ",
                          "NZ-CHAT",
                          "Navajo",
                          "PRC",
                          "PST8PDT",
                          "Pacific/Apia",
                          "Pacific/Auckland",
                          "Pacific/Bougainville",
                          "Pacific/Chatham",
                          "Pacific/Chuuk",
                          "Pacific/Easter",
                          "Pacific/Efate",
                          "Pacific/Enderbury",
                          "Pacific/Fakaofo",
                          "Pacific/Fiji",
                          "Pacific/Funafuti",
                          "Pacific/Galapagos",
                          "Pacific/Gambier",
                          "Pacific/Guadalcanal",
                          "Pacific/Guam",
                          "Pacific/Honolulu",
                          "Pacific/Johnston",
                          "Pacific/Kanton",
                          "Pacific/Kiritimati",
                          "Pacific/Kosrae",
                          "Pacific/Kwajalein",
                          "Pacific/Majuro",
                          "Pacific/Marquesas",
                          "Pacific/Midway",
                          "Pacific/Nauru",
                          "Pacific/Niue",
                          "Pacific/Norfolk",
                          "Pacific/Noumea",
                          "Pacific/Pago_Pago",
                          "Pacific/Palau",
                          "Pacific/Pitcairn",
                          "Pacific/Pohnpei",
                          "Pacific/Ponape",
                          "Pacific/Port_Moresby",
                          "Pacific/Rarotonga",
                          "Pacific/Saipan",
                          "Pacific/Samoa",
                          "Pacific/Tahiti",
                          "Pacific/Tarawa",
                          "Pacific/Tongatapu",
                          "Pacific/Truk",
                          "Pacific/Wake",
                          "Pacific/Wallis",
                          "Pacific/Yap",
                          "Poland",
                          "Portugal",
                          "ROC",
                          "ROK",
                          "Singapore",
                          "Turkey",
                          "UCT",
                          "US/Alaska",
                          "US/Aleutian",
                          "US/Arizona",
                          "US/Central",
                          "US/East-Indiana",
                          "US/Eastern",
                          "US/Hawaii",
                          "US/Indiana-Starke",
                          "US/Michigan",
                          "US/Mountain",
                          "US/Pacific",
                          "US/Samoa",
                          "UTC",
                          "Universal",
                          "W-SU",
                          "WET",
                          "Zulu"
                        ],
                        "title": "Timezone",
                        "type": "string"
                      }
                    },
                    "description": "Returns the current date and time in the selected timezone.",
                    "display_description": "Returns the current date and time in the selected timezone.",
                    "display_name": "get_current_date",
                    "name": "get_current_date",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "get_current_date"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "CurrentDate"
        },
        "dragging": false,
        "id": "CurrentDate-zvJtP",
        "measured": {
          "height": 218,
          "width": 320
        },
        "position": {
          "x": 1233.8350938335345,
          "y": -431.59296861620066
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-9skbh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.128.0"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-9skbh",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 2522.7291029146127,
          "y": 305.3328865957802
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-WmeJG",
          "node": {
            "description": "## 📋 How to Use\n\nProvide these 6 details in your message:\n- Product\n- Target Audience\n- Benefits\n- Tone of Voice\n- Platform (Google Ads, Facebook, etc.)\n- Number of Variations\n\nThe agent will collect the info, research platform specs, and generate optimized ad copy variations.\n\n**Example:**\n\"Facebook Ads for B2B SaaS. Target: small business owners. Benefits: productivity, collaboration. Tone: professional. 5 variations.\"",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 526,
        "id": "note-WmeJG",
        "measured": {
          "height": 526,
          "width": 341
        },
        "position": {
          "x": 239.07994601912873,
          "y": -536.3719981356959
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 341
      }
    ],
    "viewport": {
      "x": 317.6054195535571,
      "y": 265.04569333578877,
      "zoom": 0.35004138661110434
    }
  },
  "description": "Building Linguistic Labyrinths.",
  "endpoint_name": null,
  "id": "f791254b-1059-4001-8060-de34613e87df",
  "is_component": false,
  "last_tested_version": "1.8.0",
  "name": "Ad Copy Variation Generator",
  "tags": []
}