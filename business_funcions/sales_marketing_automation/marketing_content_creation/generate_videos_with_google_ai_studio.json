{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-XJ8Fr",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "prompt",
            "id": "CustomComponent-A6PEl",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-XJ8Fr{œdataTypeœ:œChatInputœ,œidœ:œChatInput-XJ8Frœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-A6PEl{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-A6PElœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-XJ8Fr",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-XJ8Frœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-A6PEl",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-A6PElœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleVeo2VideoGenerator",
            "id": "CustomComponent-A6PEl",
            "name": "video_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-SIkTI",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-A6PEl{œdataTypeœ:œGoogleVeo2VideoGeneratorœ,œidœ:œCustomComponent-A6PElœ,œnameœ:œvideo_dataœ,œoutput_typesœ:[œDataœ]}-ChatOutput-SIkTI{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SIkTIœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "CustomComponent-A6PEl",
        "sourceHandle": "{œdataTypeœ:œGoogleVeo2VideoGeneratorœ,œidœ:œCustomComponent-A6PElœ,œnameœ:œvideo_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ChatOutput-SIkTI",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SIkTIœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-XJ8Fr",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.7.1",
            "metadata": {
              "code_hash": "7a26c54d89ed",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        # Filter out None/empty values\n        files = [f for f in files if f is not None and f != \"\"]\n\n        session_id = self.session_id or self.graph.session_id or \"\"\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=session_id,\n            context_id=self.context_id,\n            files=files,\n        )\n        if session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-XJ8Fr",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": 149.00000448447264,
          "y": 420
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-A6PEl",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate videos using the official Google Veo.",
            "display_name": "Google Video Generator",
            "documentation": "",
            "edited": true,
            "field_order": [
              "api_key",
              "model",
              "prompt",
              "aspect_ratio",
              "allow_people"
            ],
            "frozen": false,
            "icon": "Google",
            "legacy": false,
            "lf_version": "1.7.1",
            "metadata": {
              "code_hash": "fa82048042fc",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  },
                  {
                    "name": "google",
                    "version": "1.56.0"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "custom_components.google_video_generator"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Video Data",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build",
                "name": "video_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Playground Video",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "generate_playground_video",
                "name": "playground_video",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_people": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Allow People",
                "dynamic": false,
                "external_options": {},
                "info": "Whether to allow people generation in videos",
                "load_from_db": false,
                "name": "allow_people",
                "options": [
                  "default",
                  "allow_adult"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "default"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Your API key for authentication with the Gemini SDK.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "aspect_ratio": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Aspect Ratio",
                "dynamic": false,
                "external_options": {},
                "info": "Video format ratio",
                "name": "aspect_ratio",
                "options": [
                  "16:9",
                  "9:16"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "16:9"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import time\r\nfrom lfx.custom import Component\r\nfrom lfx.io import StrInput, MultilineInput, SecretStrInput, Output, DropdownInput\r\nfrom lfx.schema import Data, Message\r\n\r\nfrom google import genai\r\nfrom google.genai import types\r\n\r\nclass GoogleVeoVideoGenerator(Component):\r\n    display_name = \"Google Video Generator\"\r\n    description = \"Generate videos using the official Google Veo.\"\r\n    icon = \"Google\"\r\n    name = \"GoogleVeo2VideoGenerator\"\r\n\r\n    field_order = [\"api_key\", \"model\", \"prompt\", \"aspect_ratio\", \"allow_people\"]\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"Your API key for authentication with the Gemini SDK.\",\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"model\",\r\n            display_name=\"Model\",\r\n            info=\"Veo model to use for video generation\",\r\n            options=[\r\n                \"veo-3.1-generate-preview\",\r\n                \"veo-3.0-generate-001\",  # Latest Veo 3.0 model (stable)\r\n                \"veo-3.0-generate-preview\",  # Veo 3.0 preview model\r\n                \"models/veo-3.0-generate-001\",  # Full format for Veo 3.0\r\n                \"models/veo-3.0-generate-preview\",  # Full format for Veo 3.0 preview\r\n                \"veo-2.0-generate-001\",  # Veo 2.0 model (requires GCP billing)\r\n                \"models/veo-2.0-generate-001\",  # Full format for Veo 2.0\r\n            ],\r\n            value=\"veo-3.0-generate-001\",  # Default to latest Veo 3.0\r\n        ),\r\n        MultilineInput(\r\n            name=\"prompt\",\r\n            display_name=\"Prompt\",\r\n            info=\"Text prompt to generate the video.\",\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"aspect_ratio\",\r\n            display_name=\"Aspect Ratio\",\r\n            info=\"Video format ratio\",\r\n            options=[\r\n                \"16:9\",  # Widescreen\r\n                \"9:16\",  # Portrait/Vertical\r\n            ],\r\n            value=\"16:9\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"allow_people\",\r\n            display_name=\"Allow People\",\r\n            info=\"Whether to allow people generation in videos\",\r\n            options=[\r\n                \"default\",  # Use model default behavior\r\n                \"allow_adult\",  # Allow adult people\r\n            ],\r\n            value=\"default\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"video_data\", display_name=\"Video Data\", method=\"build\"),\r\n        Output(name=\"playground_video\", display_name=\"Playground Video\", method=\"generate_playground_video\"),\r\n    ]\r\n\r\n    def build(self) -> Data:\r\n        try:\r\n            # Create client with API key directly (correct way for Google GenAI SDK)\r\n            client = genai.Client(api_key=self.api_key)\r\n\r\n            # Generate video using the selected model\r\n            # Only set person_generation when explicitly requested; some models\r\n            # do not support \"dont_allow\" and default is safer.\r\n            config_kwargs = {\r\n                \"aspect_ratio\": self.aspect_ratio,\r\n            }\r\n            if self.allow_people != \"default\":\r\n                config_kwargs[\"person_generation\"] = self.allow_people\r\n\r\n            operation = client.models.generate_videos(\r\n                model=self.model,  # Use selected model instead of hardcoded\r\n                prompt=self.prompt,\r\n                config=types.GenerateVideosConfig(**config_kwargs),\r\n            )\r\n\r\n            self.status = f\"Waiting for video generation completion using {self.model}...\"\r\n            \r\n            # Poll for completion with proper interval (20 seconds as per documentation)\r\n            while not operation.done:\r\n                time.sleep(20)\r\n                operation = client.operations.get(operation)\r\n\r\n            # Process generated videos according to documentation\r\n            video_urls = []\r\n            video_data = []\r\n            \r\n            for n, generated_video in enumerate(operation.response.generated_videos):\r\n                if hasattr(generated_video, 'video') and generated_video.video:\r\n                    video_info = {\r\n                        \"video_id\": n,\r\n                        \"video_object\": generated_video.video\r\n                    }\r\n                    \r\n                    # Add URI if available (needs API key appended for download)\r\n                    if hasattr(generated_video.video, 'uri'):\r\n                        video_url = f\"{generated_video.video.uri}&key={self.api_key}\"\r\n                        video_info[\"video_uri\"] = video_url\r\n                        video_urls.append(video_url)\r\n                    \r\n                    video_data.append(video_info)\r\n\r\n            if not video_data:\r\n                raise ValueError(\"No video was generated.\")\r\n\r\n            self.status = f\"Video(s) generated successfully using {self.model}. Total: {len(video_data)}\"\r\n            \r\n            # Return the first video URL as main output, with detailed data available\r\n            primary_video_url = video_urls[0] if video_urls else None\r\n            \r\n            return Data(data={\r\n                \"video_url\": primary_video_url,  # Direct link to first video\r\n                \"video_urls\": video_urls,        # List of all links\r\n                \"video_count\": len(video_data),\r\n                \"videos\": video_data,            # Complete data\r\n                \"model_used\": self.model,        # Model used\r\n                \"prompt_used\": self.prompt,\r\n                \"aspect_ratio\": self.aspect_ratio\r\n            })\r\n\r\n        except Exception as e:\r\n            error_message = str(e)\r\n            self.status = f\"Error with model {self.model}: {error_message}\"\r\n            \r\n            # Provide helpful error info\r\n            return Data(data={\r\n                \"error\": error_message,\r\n                \"model_attempted\": self.model,\r\n                \"video_count\": 0,\r\n                \"suggestion\": \"Try using veo-3.0-generate-001 for the latest model, or check your API key and billing setup\"\r\n            })\r\n\r\n    def generate_playground_video(self) -> Message:\r\n        \"\"\"Generate HTML video player code for the generated video.\"\"\"\r\n        try:\r\n            # First, generate the video using the build method\r\n            video_result = self.build()\r\n            \r\n            # Check if video generation was successful\r\n            if hasattr(video_result, 'data') and isinstance(video_result.data, dict):\r\n                if 'error' in video_result.data:\r\n                    return Message(text=f\"Error: {video_result.data['error']}\")\r\n                \r\n                # Get the primary video URL\r\n                video_url = video_result.data.get('video_url')\r\n                if not video_url:\r\n                    return Message(text=\"Error: No video URL generated\")\r\n                \r\n                # Determine aspect ratio for dimensions\r\n                aspect_ratio = self.aspect_ratio\r\n                if aspect_ratio == \"16:9\":\r\n                    width, height = 640, 360\r\n                elif aspect_ratio == \"9:16\":\r\n                    width, height = 360, 640\r\n                else:\r\n                    width, height = 640, 360  # Default to 16:9\r\n                \r\n                # Generate HTML video player code\r\n                html_code = f'<video width=\"{width}\" height=\"{height}\" controls>\\n  <source src=\"{video_url}\">\\n</video>'\r\n                \r\n                self.status = f\"Generated playground video HTML for {aspect_ratio} aspect ratio\"\r\n                return Message(text=html_code)\r\n            else:\r\n                return Message(text=\"Error: Invalid video generation result\")\r\n                \r\n        except Exception as e:\r\n            error_msg = f\"Error generating playground video: {str(e)}\"\r\n            self.status = f\"Error: {error_msg}\"\r\n            return Message(text=f\"Error: {error_msg}\")\r\n"
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "Veo model to use for video generation",
                "name": "model",
                "options": [
                  "veo-3.1-generate-preview",
                  "veo-3.0-generate-001",
                  "veo-3.0-generate-preview",
                  "models/veo-3.0-generate-001",
                  "models/veo-3.0-generate-preview",
                  "veo-2.0-generate-001",
                  "models/veo-2.0-generate-001"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "veo-3.0-generate-001"
              },
              "prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Prompt",
                "dynamic": false,
                "info": "Text prompt to generate the video.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "prompt",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "video_data",
          "showNode": true,
          "type": "GoogleVeo2VideoGenerator"
        },
        "id": "CustomComponent-A6PEl",
        "measured": {
          "height": 531,
          "width": 320
        },
        "position": {
          "x": 527,
          "y": 420
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-SIkTI",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.7.1",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.127.0"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-SIkTI",
        "measured": {
          "height": 165,
          "width": 320
        },
        "position": {
          "x": 913,
          "y": 420
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-xhxiq",
          "node": {
            "description": "The Google Video Generator component has two output types.\n\nPlayground Video: Uses the download link generated by the API to generate appropriate markdown for creating the video in the playground.\n\nVideo Data (more appropriate for use via API): Generates a data (JSON) file with the data returned by the API, including the video download link.",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-xhxiq",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 525,
          "y": 55.999999492323866
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 324
      }
    ],
    "viewport": {
      "x": 124.18547342559566,
      "y": -8.423463268857802,
      "zoom": 0.7754189939735624
    }
  },
  "description": "Navigate the Networks of Conversation.",
  "endpoint_name": null,
  "id": "40af0995-9cbe-4a68-a11c-abad95fb3fec",
  "is_component": false,
  "last_tested_version": "1.7.1",
  "name": "generate_videos_with_google_ai_studio",
  "tags": []
}