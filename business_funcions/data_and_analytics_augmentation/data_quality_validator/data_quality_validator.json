{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MockDataGenerator",
            "id": "MockDataGenerator-yi33Q",
            "name": "dataframe_output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-ogMLJ",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__MockDataGenerator-yi33Q{œdataTypeœ:œMockDataGeneratorœ,œidœ:œMockDataGenerator-yi33Qœ,œnameœ:œdataframe_outputœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-ogMLJ{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MockDataGenerator-yi33Q",
        "sourceHandle": "{œdataTypeœ:œMockDataGeneratorœ,œidœ:œMockDataGenerator-yi33Qœ,œnameœ:œdataframe_outputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-ogMLJ",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-fda3w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-ogMLJ",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LanguageModelComponent-fda3w{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-fda3wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-ogMLJ{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LanguageModelComponent-fda3w",
        "sourceHandle": "{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-fda3wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-ogMLJ",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-ogMLJ",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-vsYy3",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__BatchRunComponent-ogMLJ{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ogMLJœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-vsYy3{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-vsYy3œ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-ogMLJ",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ogMLJœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-vsYy3",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-vsYy3œ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-ogMLJ",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-rOcxC",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__BatchRunComponent-ogMLJ{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ogMLJœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-rOcxC{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-rOcxCœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-ogMLJ",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ogMLJœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-rOcxC",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-rOcxCœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataFrameOperations",
            "id": "DataFrameOperations-rOcxC",
            "name": "output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-gYOJK",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__DataFrameOperations-rOcxC{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-rOcxCœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-gYOJK{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-gYOJKœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataFrameOperations-rOcxC",
        "sourceHandle": "{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-rOcxCœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-gYOJK",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-gYOJKœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-gYOJK",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-ss9Iw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-gYOJK{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-gYOJKœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Agent-ss9Iw{œfieldNameœ:œinput_valueœ,œidœ:œAgent-ss9Iwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-gYOJK",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-gYOJKœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-ss9Iw",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-ss9Iwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-ss9Iw",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-imjMX",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-ss9Iw{œdataTypeœ:œAgentœ,œidœ:œAgent-ss9Iwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-imjMX{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-imjMXœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-ss9Iw",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-ss9Iwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-imjMX",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-imjMXœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-4UjbK",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-ogMLJ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-4UjbK{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-4UjbKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-ogMLJ{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-4UjbK",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-4UjbKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-ogMLJ",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-ogMLJœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "MockDataGenerator-yi33Q",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate mock data for testing and development.",
            "display_name": "Mock Data",
            "documentation": "",
            "edited": false,
            "field_order": [],
            "frozen": false,
            "icon": "database",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "d21dce7b329b",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  },
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.data_source.mock_data.MockDataGeneratorComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "method": "generate_dataframe_output",
                "name": "dataframe_output",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "method": "generate_message_output",
                "name": "message_output",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "method": "generate_data_output",
                "name": "data_output",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import secrets\nfrom datetime import datetime, timedelta, timezone\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import Output\nfrom lfx.schema import Data, DataFrame\nfrom lfx.schema.message import Message\n\n\nclass MockDataGeneratorComponent(Component):\n    \"\"\"Mock Data Generator Component.\n\n    Generates sample data for testing and development purposes. Supports three main\n    Langflow output types: Message (text), Data (JSON), and DataFrame (tabular data).\n\n    This component is useful for:\n    - Testing workflows without real data sources\n    - Prototyping data processing pipelines\n    - Creating sample data for demonstrations\n    - Development and debugging of Langflow components\n    \"\"\"\n\n    display_name = \"Mock Data\"\n    description = \"Generate mock data for testing and development.\"\n    icon = \"database\"\n    name = \"MockDataGenerator\"\n\n    inputs = []\n\n    outputs = [\n        Output(display_name=\"Result\", name=\"dataframe_output\", method=\"generate_dataframe_output\"),\n        Output(display_name=\"Result\", name=\"message_output\", method=\"generate_message_output\"),\n        Output(display_name=\"Result\", name=\"data_output\", method=\"generate_data_output\"),\n    ]\n\n    def build(self) -> DataFrame:\n        \"\"\"Default build method - returns DataFrame when component is standalone.\"\"\"\n        return self.generate_dataframe_output()\n\n    def generate_message_output(self) -> Message:\n        \"\"\"Generate Message output specifically.\n\n        Returns:\n            Message: A Message object containing Lorem Ipsum text\n        \"\"\"\n        try:\n            self.log(\"Generating Message mock data\")\n            message = self._generate_message()\n            self.status = f\"Generated Lorem Ipsum message ({len(message.text)} characters)\"\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating Message data: {e!s}\"\n            self.log(error_msg)\n            self.status = f\"Error: {error_msg}\"\n            return Message(text=f\"Error: {error_msg}\")\n        else:\n            return message\n\n    def generate_data_output(self) -> Data:\n        \"\"\"Generate Data output specifically.\n\n        Returns:\n            Data: A Data object containing sample JSON data (1 record)\n        \"\"\"\n        try:\n            record_count = 1  # Fixed to 1 record for Data output\n            self.log(f\"Generating Data mock data with {record_count} record\")\n            data = self._generate_data(record_count)\n            self.status = f\"Generated JSON data with {len(data.data.get('records', []))} record(s)\"\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating Data: {e!s}\"\n            self.log(error_msg)\n            self.status = f\"Error: {error_msg}\"\n            return Data(data={\"error\": error_msg, \"success\": False})\n        else:\n            return data\n\n    def generate_dataframe_output(self) -> DataFrame:\n        \"\"\"Generate DataFrame output specifically.\n\n        Returns:\n            DataFrame: A Langflow DataFrame with sample data (50 records)\n        \"\"\"\n        try:\n            record_count = 50  # Fixed to 50 records for DataFrame output\n            self.log(f\"Generating DataFrame mock data with {record_count} records\")\n            return self._generate_dataframe(record_count)\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating DataFrame: {e!s}\"\n            self.log(error_msg)\n\n            try:\n                import pandas as pd\n\n                error_df = pd.DataFrame({\"error\": [error_msg]})\n                return DataFrame(error_df)\n            except ImportError:\n                # Even without pandas, return DataFrame wrapper\n                return DataFrame({\"error\": [error_msg]})\n\n    def _generate_message(self) -> Message:\n        \"\"\"Generate a sample Message with Lorem Ipsum text.\n\n        Returns:\n            Message: A Message object containing Lorem Ipsum text\n        \"\"\"\n        lorem_ipsum_texts = [\n            (\n                \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor \"\n                \"incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud \"\n                \"exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n            ),\n            (\n                \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla \"\n                \"pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt \"\n                \"mollit anim id est laborum.\"\n            ),\n            (\n                \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, \"\n                \"totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto \"\n                \"beatae vitae dicta sunt explicabo.\"\n            ),\n            (\n                \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, \"\n                \"sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\"\n            ),\n            (\n                \"Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, \"\n                \"adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore \"\n                \"magnam aliquam quaerat voluptatem.\"\n            ),\n        ]\n\n        selected_text = secrets.choice(lorem_ipsum_texts)\n        return Message(text=selected_text)\n\n    def _generate_data(self, record_count: int) -> Data:\n        \"\"\"Generate sample Data with JSON structure.\n\n        Args:\n            record_count: Number of records to generate\n\n        Returns:\n            Data: A Data object containing sample JSON data\n        \"\"\"\n        # Sample data categories\n        companies = [\n            \"TechCorp\",\n            \"DataSystems\",\n            \"CloudWorks\",\n            \"InnovateLab\",\n            \"DigitalFlow\",\n            \"SmartSolutions\",\n            \"FutureTech\",\n            \"NextGen\",\n        ]\n        departments = [\"Engineering\", \"Sales\", \"Marketing\", \"HR\", \"Finance\", \"Operations\", \"Support\", \"Research\"]\n        statuses = [\"active\", \"pending\", \"completed\", \"cancelled\", \"in_progress\"]\n        categories = [\"A\", \"B\", \"C\", \"D\"]\n\n        # Generate sample records\n        records = []\n        base_date = datetime.now(tz=timezone.utc) - timedelta(days=365)\n\n        for i in range(record_count):\n            record = {\n                \"id\": f\"REC-{1000 + i}\",\n                \"name\": f\"Sample Record {i + 1}\",\n                \"company\": secrets.choice(companies),\n                \"department\": secrets.choice(departments),\n                \"status\": secrets.choice(statuses),\n                \"category\": secrets.choice(categories),\n                \"value\": round(secrets.randbelow(9901) + 100 + secrets.randbelow(100) / 100, 2),\n                \"quantity\": secrets.randbelow(100) + 1,\n                \"rating\": round(secrets.randbelow(41) / 10 + 1, 1),\n                \"is_active\": secrets.choice([True, False]),\n                \"created_date\": (base_date + timedelta(days=secrets.randbelow(366))).isoformat(),\n                \"tags\": [\n                    secrets.choice(\n                        [\n                            \"important\",\n                            \"urgent\",\n                            \"review\",\n                            \"approved\",\n                            \"draft\",\n                            \"final\",\n                        ]\n                    )\n                    for _ in range(secrets.randbelow(3) + 1)\n                ],\n            }\n            records.append(record)\n\n        # Create the main data structure\n        data_structure = {\n            \"records\": records,\n            \"summary\": {\n                \"total_count\": record_count,\n                \"active_count\": sum(1 for r in records if r[\"is_active\"]),\n                \"total_value\": sum(r[\"value\"] for r in records),\n                \"average_rating\": round(sum(r[\"rating\"] for r in records) / record_count, 2),\n                \"categories\": list({r[\"category\"] for r in records}),\n                \"companies\": list({r[\"company\"] for r in records}),\n            },\n        }\n\n        return Data(data=data_structure)\n\n    def _generate_dataframe(self, record_count: int) -> DataFrame:\n        \"\"\"Generate sample DataFrame with realistic business data.\n\n        Args:\n            record_count: Number of rows to generate\n\n        Returns:\n            DataFrame: A Langflow DataFrame with sample data\n        \"\"\"\n        try:\n            import pandas as pd\n\n            self.log(f\"pandas imported successfully, version: {pd.__version__}\")\n        except ImportError as e:\n            self.log(f\"pandas not available: {e!s}, creating simple DataFrame fallback\")\n            # Create a simple DataFrame-like structure without pandas\n            data_result = self._generate_data(record_count)\n            # Convert Data to simple DataFrame format\n            try:\n                # Create a basic DataFrame structure from the Data\n                records = data_result.data.get(\"records\", [])\n                if records:\n                    # Use first record to get column names\n                    columns = list(records[0].keys()) if records else [\"error\"]\n                    rows = [list(record.values()) for record in records]\n                else:\n                    columns = [\"error\"]\n                    rows = [[\"pandas not available\"]]\n\n                # Create a simple dict-based DataFrame representation\n                simple_df_data = {\n                    col: [row[i] if i < len(row) else None for row in rows] for i, col in enumerate(columns)\n                }\n\n                # Return as DataFrame wrapper (Langflow will handle the display)\n                return DataFrame(simple_df_data)\n            except (ValueError, TypeError):\n                # Ultimate fallback - return the Data as DataFrame\n                return DataFrame({\"data\": [str(data_result.data)]})\n\n        try:\n            self.log(f\"Starting DataFrame generation with {record_count} records\")\n\n            # Sample data for realistic business dataset\n            first_names = [\n                \"John\",\n                \"Jane\",\n                \"Michael\",\n                \"Sarah\",\n                \"David\",\n                \"Emily\",\n                \"Robert\",\n                \"Lisa\",\n                \"William\",\n                \"Jennifer\",\n            ]\n            last_names = [\n                \"Smith\",\n                \"Johnson\",\n                \"Williams\",\n                \"Brown\",\n                \"Jones\",\n                \"Garcia\",\n                \"Miller\",\n                \"Davis\",\n                \"Rodriguez\",\n                \"Martinez\",\n            ]\n            cities = [\n                \"New York\",\n                \"Los Angeles\",\n                \"Chicago\",\n                \"Houston\",\n                \"Phoenix\",\n                \"Philadelphia\",\n                \"San Antonio\",\n                \"San Diego\",\n                \"Dallas\",\n                \"San Jose\",\n            ]\n            countries = [\"USA\", \"Canada\", \"UK\", \"Germany\", \"France\", \"Australia\", \"Japan\", \"Brazil\", \"India\", \"Mexico\"]\n            products = [\n                \"Product A\",\n                \"Product B\",\n                \"Product C\",\n                \"Product D\",\n                \"Product E\",\n                \"Service X\",\n                \"Service Y\",\n                \"Service Z\",\n            ]\n\n            # Generate DataFrame data\n            data = []\n            base_date = datetime.now(tz=timezone.utc) - timedelta(days=365)\n\n            self.log(\"Generating row data...\")\n            for i in range(record_count):\n                row = {\n                    \"customer_id\": f\"CUST-{10000 + i}\",\n                    \"first_name\": secrets.choice(first_names),\n                    \"last_name\": secrets.choice(last_names),\n                    \"email\": f\"user{i + 1}@example.com\",\n                    \"age\": secrets.randbelow(63) + 18,\n                    \"city\": secrets.choice(cities),\n                    \"country\": secrets.choice(countries),\n                    \"product\": secrets.choice(products),\n                    \"order_date\": (base_date + timedelta(days=secrets.randbelow(366))).strftime(\"%Y-%m-%d\"),\n                    \"order_value\": round(secrets.randbelow(991) + 10 + secrets.randbelow(100) / 100, 2),\n                    \"quantity\": secrets.randbelow(10) + 1,\n                    \"discount\": round(secrets.randbelow(31) / 100, 2),\n                    \"is_premium\": secrets.choice([True, False]),\n                    \"satisfaction_score\": secrets.randbelow(10) + 1,\n                    \"last_contact\": (base_date + timedelta(days=secrets.randbelow(366))).strftime(\"%Y-%m-%d\"),\n                }\n                data.append(row)\n            # Create DataFrame\n            self.log(\"Creating pandas DataFrame...\")\n            df = pd.DataFrame(data)\n            self.log(f\"DataFrame created with shape: {df.shape}\")\n\n            # Add calculated columns\n            self.log(\"Adding calculated columns...\")\n            df[\"full_name\"] = df[\"first_name\"] + \" \" + df[\"last_name\"]\n            df[\"discounted_value\"] = df[\"order_value\"] * (1 - df[\"discount\"])\n            df[\"total_value\"] = df[\"discounted_value\"] * df[\"quantity\"]\n\n            # Age group boundaries as constants\n            age_group_18_25 = 25\n            age_group_26_35 = 35\n            age_group_36_50 = 50\n            age_group_51_65 = 65\n\n            # Create age groups with better error handling\n            try:\n                df[\"age_group\"] = pd.cut(\n                    df[\"age\"],\n                    bins=[\n                        0,\n                        age_group_18_25,\n                        age_group_26_35,\n                        age_group_36_50,\n                        age_group_51_65,\n                        100,\n                    ],\n                    labels=[\n                        \"18-25\",\n                        \"26-35\",\n                        \"36-50\",\n                        \"51-65\",\n                        \"65+\",\n                    ],\n                )\n            except (ValueError, TypeError) as e:\n                self.log(f\"Error creating age groups with pd.cut: {e!s}, using simple categorization\")\n                df[\"age_group\"] = df[\"age\"].apply(\n                    lambda x: \"18-25\"\n                    if x <= age_group_18_25\n                    else \"26-35\"\n                    if x <= age_group_26_35\n                    else \"36-50\"\n                    if x <= age_group_36_50\n                    else \"51-65\"\n                    if x <= age_group_51_65\n                    else \"65+\"\n                )\n\n            self.log(f\"Successfully generated DataFrame with shape: {df.shape}, columns: {list(df.columns)}\")\n            # CRITICAL: Use DataFrame wrapper from Langflow\n            # DO NOT set self.status when returning DataFrames - it interferes with display\n            return DataFrame(df)\n\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating DataFrame: {e!s}\"\n            self.log(error_msg)\n            # DO NOT set self.status when returning DataFrames - it interferes with display\n            # Return a fallback DataFrame with error info using Langflow wrapper\n            try:\n                error_df = pd.DataFrame(\n                    {\n                        \"error\": [error_msg],\n                        \"timestamp\": [datetime.now(tz=timezone.utc).isoformat()],\n                        \"attempted_records\": [record_count],\n                    }\n                )\n                return DataFrame(error_df)\n            except (ValueError, TypeError) as fallback_error:\n                # Last resort: return simple error DataFrame\n                self.log(f\"Fallback also failed: {fallback_error!s}\")\n                simple_error_df = pd.DataFrame({\"error\": [error_msg]})\n                return DataFrame(simple_error_df)\n"
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe_output",
          "showNode": true,
          "type": "MockDataGenerator"
        },
        "dragging": false,
        "id": "MockDataGenerator-yi33Q",
        "measured": {
          "height": 121,
          "width": 320
        },
        "position": {
          "x": 484.78040554140637,
          "y": 648.2794730008459
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-ogMLJ",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row. If the LLM returns JSON, it creates new columns automatically.",
            "display_name": "Custom Batch Run",
            "documentation": "https://docs.langflow.org/batch-run",
            "edited": true,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "legacy": false,
            "metadata": {
              "code_hash": "d89122cbc435",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "toml",
                    "version": "0.10.2"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.2"
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.83"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "custom_components.custom_batch_run"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "run_batch",
                "name": "batch_results",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\nfrom datetime import datetime\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Custom Batch Run\"\n    description = \"Runs an LLM on each row. If the LLM returns JSON, it creates new columns automatically.\"\n    documentation: str = \"https://docs.langflow.org/batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction. Ask for JSON output here to generate columns.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame input.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to process. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the raw model response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with original columns + new columns from JSON response.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Cria a linha e remove a resposta bruta se o JSON for válido.\"\"\"\n        row = original_row.copy()\n        \n        # 1. Primeiro, colocamos a resposta bruta (caso dê erro, ela fica aqui)\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n\n        try:\n            import json\n            import re\n            \n            # Limpeza do Markdown\n            clean_text = model_response.strip()\n            match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", clean_text, re.DOTALL)\n            \n            if match:\n                clean_text = match.group(1)\n            else:\n                start_idx = clean_text.find(\"{\")\n                end_idx = clean_text.rfind(\"}\")\n                if start_idx != -1 and end_idx != -1:\n                    clean_text = clean_text[start_idx : end_idx + 1]\n\n            # Parse do JSON\n            data = json.loads(clean_text)\n\n            if isinstance(data, dict):\n                # Adiciona as colunas novas (status, descricao, etc)\n                for key, val in data.items():\n                    row[key] = val\n                \n                # --- A MUDANÇA ESTÁ AQUI ---\n                # Se chegou até aqui, o JSON funcionou. \n                # Então, removemos a coluna 'model_response' para limpar a tabela.\n                if self.output_column_name in row:\n                    del row[self.output_column_name]\n\n        except (json.JSONDecodeError, AttributeError, ValueError):\n            # Se der erro, não fazemos nada. \n            # A coluna 'model_response' continuará lá para você ver o que deu errado.\n            pass\n\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n        base_system_msg = self.system_message or \"\"\n        \n        system_msg = f\"{base_system_msg}\\n\\nTEMPORAL CONTEXT (IMPORTANT):\\nToday is: {current_date}. Use this date to validate future dates.\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model\n            try:\n                model = model.with_config(\n                    {\n                        \"run_name\": self.display_name,\n                        \"project_name\": self.get_project_name(),\n                        \"callbacks\": self.get_langchain_callbacks(),\n                    }\n                )\n            except (TypeError, ValueError, AttributeError) as e:\n                await logger.awarning(\n                    f\"Could not configure model with callbacks: {e!s}. Proceeding without config.\"\n                )\n\n            # Process batches\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                \n                # This calls our modified method that extracts JSON columns\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to process. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame input.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the raw model response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "model_response"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction. Ask for JSON output here to generate columns.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are a Senior Data Quality Auditor. Your analysis must be skeptical, rigorous, and EXHAUSTIVE.  INPUT DATA (JSON/TOML): Analyze each field by cross-referencing the information.  VALIDATION RULES (STRICT CRITERIA):  1. SYNTAX AND FORMAT:    - customer_id: MUST follow the strict pattern \"CUST-\" followed by numbers (e.g., \"CUST-10045\").    - email: MUST be a syntactically valid email (user + \"@\" + domain + \".\" + extension).    - order_date: MUST be in YYYY-MM-DD format.  2. BUSINESS RULES (LIMITS & PRECISION):    - age: Allowed only between 18 and 100 years old.    - order_value: MUST be strictly greater than 0.00.      - **DECIMAL PRECISION RULE:** Values MUST NOT have more than 4 decimal places.      - Example: \"100.1234\" is VALID. \"100.12345\" is INVALID. \"100.123400001\" is INVALID (Floating point artifact).    - quantity: MUST be an integer greater than or equal to 1.    - discount: MUST be a float between 0.00 and 0.50.      - **PRECISION:** Max 4 decimal places. Any floating point noise (e.g., 0.300000004) is INVALID.    - satisfaction_score: Integer strictly between 1 and 10.  3. LOGICAL CONSISTENCY (DATA CROSS-REFERENCING):    - Geographic: The 'city' MUST belong to the reported 'country'.    - Temporal: The 'order_date' CANNOT be a future date (compare with current date context).  MANDATORY OUTPUT (STRICT JSON): Check ALL rules. Do NOT stop at the first error. Accumulate all violations found.  If ANY violation is found: {{     \"status\": \"INVALID\",     \"error_field\": \"list all failed fields separated by comma (e.g., order_value, discount)\",     \"description\": \"list all reasons separated by semicolon (e.g., Value has floating point noise; Discount precision error)\" }}  If it passes ALL rules without exception: {{     \"status\": \"VALID\",     \"error_field\": null,     \"description\": null }}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-ogMLJ",
        "measured": {
          "height": 389,
          "width": 320
        },
        "position": {
          "x": 965.5183241281292,
          "y": 280.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-fda3w",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": false,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "base_url_ibm_watsonx",
              "project_id",
              "ollama_base_url",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2026-01-30T00:01:53.777Z",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "694ffc4b17b8",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "requests",
                    "version": "2.32.5"
                  },
                  {
                    "name": "langchain_anthropic",
                    "version": "0.3.14"
                  },
                  {
                    "name": "langchain_ibm",
                    "version": "0.3.20"
                  },
                  {
                    "name": "langchain_ollama",
                    "version": "0.3.10"
                  },
                  {
                    "name": "langchain_openai",
                    "version": "0.3.35"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 7
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.models_and_agents.language_model.LanguageModelComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_frontend_node_flow_id": {
                "value": "0a107780-0f52-4bcb-8d7a-169daca7a578"
              },
              "_frontend_node_folder_id": {
                "value": "f36a301c-85de-4ffe-900d-dcc3002c3a4d"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "base_url_ibm_watsonx": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "watsonx API Endpoint",
                "dynamic": false,
                "external_options": {},
                "info": "The base URL of the API (IBM watsonx.ai only)",
                "name": "base_url_ibm_watsonx",
                "options": [
                  "https://us-south.ml.cloud.ibm.com",
                  "https://eu-de.ml.cloud.ibm.com",
                  "https://eu-gb.ml.cloud.ibm.com",
                  "https://au-syd.ml.cloud.ibm.com",
                  "https://jp-tok.ml.cloud.ibm.com",
                  "https://ca-tor.ml.cloud.ibm.com"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "https://us-south.ml.cloud.ibm.com"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_ibm import ChatWatsonx\nfrom langchain_ollama import ChatOllama\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom lfx.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom lfx.base.models.google_generative_ai_model import ChatGoogleGenerativeAIFixed\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.model_utils import get_ollama_models, is_valid_ollama_url\nfrom lfx.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, MessageTextInput, StrInput\nfrom lfx.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.utils.util import transform_localhost_url\n\n# IBM watsonx.ai constants\nIBM_WATSONX_DEFAULT_MODELS = [\"ibm/granite-3-2b-instruct\", \"ibm/granite-3-8b-instruct\", \"ibm/granite-13b-instruct-v2\"]\nIBM_WATSONX_URLS = [\n    \"https://us-south.ml.cloud.ibm.com\",\n    \"https://eu-de.ml.cloud.ibm.com\",\n    \"https://eu-gb.ml.cloud.ibm.com\",\n    \"https://au-syd.ml.cloud.ibm.com\",\n    \"https://jp-tok.ml.cloud.ibm.com\",\n    \"https://ca-tor.ml.cloud.ibm.com\",\n]\n\n# Ollama API constants\nHTTP_STATUS_OK = 200\nJSON_MODELS_KEY = \"models\"\nJSON_NAME_KEY = \"name\"\nJSON_CAPABILITIES_KEY = \"capabilities\"\nDESIRED_CAPABILITY = \"completion\"\nDEFAULT_OLLAMA_URL = \"http://localhost:11434\"\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider.\"\n    documentation: str = \"https://docs.langflow.org/components-models\"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    @staticmethod\n    def fetch_ibm_models(base_url: str) -> list[str]:\n        \"\"\"Fetch available models from the watsonx.ai API.\"\"\"\n        try:\n            endpoint = f\"{base_url}/ml/v1/foundation_model_specs\"\n            params = {\"version\": \"2024-09-16\", \"filters\": \"function_text_chat,!lifecycle_withdrawn\"}\n            response = requests.get(endpoint, params=params, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            models = [model[\"model_id\"] for model in data.get(\"resources\", [])]\n            return sorted(models)\n        except Exception:  # noqa: BLE001\n            logger.exception(\"Error fetching IBM watsonx models. Using default models.\")\n            return IBM_WATSONX_DEFAULT_MODELS\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\", \"Google\", \"IBM watsonx.ai\", \"Ollama\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[\n                {\"icon\": \"OpenAI\"},\n                {\"icon\": \"Anthropic\"},\n                {\"icon\": \"GoogleGenerativeAI\"},\n                {\"icon\": \"WatsonxAI\"},\n                {\"icon\": \"Ollama\"},\n            ],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"base_url_ibm_watsonx\",\n            display_name=\"watsonx API Endpoint\",\n            info=\"The base URL of the API (IBM watsonx.ai only)\",\n            options=IBM_WATSONX_URLS,\n            value=IBM_WATSONX_URLS[0],\n            show=False,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"project_id\",\n            display_name=\"watsonx Project ID\",\n            info=\"The project ID associated with the foundation model (IBM watsonx.ai only)\",\n            show=False,\n            required=False,\n        ),\n        MessageTextInput(\n            name=\"ollama_base_url\",\n            display_name=\"Ollama API URL\",\n            info=f\"Endpoint of the Ollama API (Ollama only). Defaults to {DEFAULT_OLLAMA_URL}\",\n            value=DEFAULT_OLLAMA_URL,\n            show=False,\n            real_time_refresh=True,\n            load_from_db=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\n                # reasoning models do not support temperature (yet)\n                temperature = None\n\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        if provider == \"Google\":\n            if not self.api_key:\n                msg = \"Google API key is required when using Google provider\"\n                raise ValueError(msg)\n            return ChatGoogleGenerativeAIFixed(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                google_api_key=self.api_key,\n            )\n        if provider == \"IBM watsonx.ai\":\n            if not self.api_key:\n                msg = \"IBM API key is required when using IBM watsonx.ai provider\"\n                raise ValueError(msg)\n            if not self.base_url_ibm_watsonx:\n                msg = \"IBM watsonx API Endpoint is required when using IBM watsonx.ai provider\"\n                raise ValueError(msg)\n            if not self.project_id:\n                msg = \"IBM watsonx Project ID is required when using IBM watsonx.ai provider\"\n                raise ValueError(msg)\n            return ChatWatsonx(\n                apikey=SecretStr(self.api_key).get_secret_value(),\n                url=self.base_url_ibm_watsonx,\n                project_id=self.project_id,\n                model_id=model_name,\n                params={\n                    \"temperature\": temperature,\n                },\n                streaming=stream,\n            )\n        if provider == \"Ollama\":\n            if not self.ollama_base_url:\n                msg = \"Ollama API URL is required when using Ollama provider\"\n                raise ValueError(msg)\n            if not model_name:\n                msg = \"Model name is required when using Ollama provider\"\n                raise ValueError(msg)\n\n            transformed_base_url = transform_localhost_url(self.ollama_base_url)\n\n            # Check if URL contains /v1 suffix (OpenAI-compatible mode)\n            if transformed_base_url and transformed_base_url.rstrip(\"/\").endswith(\"/v1\"):\n                # Strip /v1 suffix and log warning\n                transformed_base_url = transformed_base_url.rstrip(\"/\").removesuffix(\"/v1\")\n                logger.warning(\n                    \"Detected '/v1' suffix in base URL. The Ollama component uses the native Ollama API, \"\n                    \"not the OpenAI-compatible API. The '/v1' suffix has been automatically removed. \"\n                    \"If you want to use the OpenAI-compatible API, please use the OpenAI component instead. \"\n                    \"Learn more at https://docs.ollama.com/openai#openai-compatibility\"\n                )\n\n            return ChatOllama(\n                base_url=transformed_base_url,\n                model=model_name,\n                temperature=temperature,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: Any, field_name: str | None = None\n    ) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n                build_config[\"api_key\"][\"show\"] = True\n                build_config[\"base_url_ibm_watsonx\"][\"show\"] = False\n                build_config[\"project_id\"][\"show\"] = False\n                build_config[\"ollama_base_url\"][\"show\"] = False\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n                build_config[\"api_key\"][\"show\"] = True\n                build_config[\"base_url_ibm_watsonx\"][\"show\"] = False\n                build_config[\"project_id\"][\"show\"] = False\n                build_config[\"ollama_base_url\"][\"show\"] = False\n            elif field_value == \"Google\":\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\n                build_config[\"api_key\"][\"show\"] = True\n                build_config[\"base_url_ibm_watsonx\"][\"show\"] = False\n                build_config[\"project_id\"][\"show\"] = False\n                build_config[\"ollama_base_url\"][\"show\"] = False\n            elif field_value == \"IBM watsonx.ai\":\n                build_config[\"model_name\"][\"options\"] = IBM_WATSONX_DEFAULT_MODELS\n                build_config[\"model_name\"][\"value\"] = IBM_WATSONX_DEFAULT_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"IBM API Key\"\n                build_config[\"api_key\"][\"show\"] = True\n                build_config[\"base_url_ibm_watsonx\"][\"show\"] = True\n                build_config[\"project_id\"][\"show\"] = True\n                build_config[\"ollama_base_url\"][\"show\"] = False\n            elif field_value == \"Ollama\":\n                # Fetch Ollama models from the API\n                build_config[\"api_key\"][\"show\"] = False\n                build_config[\"base_url_ibm_watsonx\"][\"show\"] = False\n                build_config[\"project_id\"][\"show\"] = False\n                build_config[\"ollama_base_url\"][\"show\"] = True\n\n                # Try multiple sources to get the URL (in order of preference):\n                # 1. Instance attribute (already resolved from global/db)\n                # 2. Build config value (may be a global variable reference)\n                # 3. Default value\n                ollama_url = getattr(self, \"ollama_base_url\", None)\n                if not ollama_url:\n                    config_value = build_config[\"ollama_base_url\"].get(\"value\", DEFAULT_OLLAMA_URL)\n                    # If config_value looks like a variable name (all caps with underscores), use default\n                    is_variable_ref = (\n                        config_value\n                        and isinstance(config_value, str)\n                        and config_value.isupper()\n                        and \"_\" in config_value\n                    )\n                    if is_variable_ref:\n                        await logger.adebug(\n                            f\"Config value appears to be a variable reference: {config_value}, using default\"\n                        )\n                        ollama_url = DEFAULT_OLLAMA_URL\n                    else:\n                        ollama_url = config_value\n\n                await logger.adebug(f\"Fetching Ollama models for provider switch. URL: {ollama_url}\")\n                if await is_valid_ollama_url(url=ollama_url):\n                    try:\n                        models = await get_ollama_models(\n                            base_url_value=ollama_url,\n                            desired_capability=DESIRED_CAPABILITY,\n                            json_models_key=JSON_MODELS_KEY,\n                            json_name_key=JSON_NAME_KEY,\n                            json_capabilities_key=JSON_CAPABILITIES_KEY,\n                        )\n                        build_config[\"model_name\"][\"options\"] = models\n                        build_config[\"model_name\"][\"value\"] = models[0] if models else \"\"\n                    except ValueError:\n                        await logger.awarning(\"Failed to fetch Ollama models. Setting empty options.\")\n                        build_config[\"model_name\"][\"options\"] = []\n                        build_config[\"model_name\"][\"value\"] = \"\"\n                else:\n                    await logger.awarning(f\"Invalid Ollama URL: {ollama_url}\")\n                    build_config[\"model_name\"][\"options\"] = []\n                    build_config[\"model_name\"][\"value\"] = \"\"\n        elif (\n            field_name == \"base_url_ibm_watsonx\"\n            and field_value\n            and hasattr(self, \"provider\")\n            and self.provider == \"IBM watsonx.ai\"\n        ):\n            # Fetch IBM models when base_url changes\n            try:\n                models = self.fetch_ibm_models(base_url=field_value)\n                build_config[\"model_name\"][\"options\"] = models\n                build_config[\"model_name\"][\"value\"] = models[0] if models else IBM_WATSONX_DEFAULT_MODELS[0]\n                info_message = f\"Updated model options: {len(models)} models found in {field_value}\"\n                logger.info(info_message)\n            except Exception:  # noqa: BLE001\n                logger.exception(\"Error updating IBM model options.\")\n        elif field_name == \"ollama_base_url\":\n            # Fetch Ollama models when ollama_base_url changes\n            # Use the field_value directly since this is triggered when the field changes\n            logger.debug(\n                f\"Fetching Ollama models from updated URL: {build_config['ollama_base_url']} \\\n                and value {self.ollama_base_url}\",\n            )\n            await logger.adebug(f\"Fetching Ollama models from updated URL: {self.ollama_base_url}\")\n            if await is_valid_ollama_url(url=self.ollama_base_url):\n                try:\n                    models = await get_ollama_models(\n                        base_url_value=self.ollama_base_url,\n                        desired_capability=DESIRED_CAPABILITY,\n                        json_models_key=JSON_MODELS_KEY,\n                        json_name_key=JSON_NAME_KEY,\n                        json_capabilities_key=JSON_CAPABILITIES_KEY,\n                    )\n                    build_config[\"model_name\"][\"options\"] = models\n                    build_config[\"model_name\"][\"value\"] = models[0] if models else \"\"\n                    info_message = f\"Updated model options: {len(models)} models found in {self.ollama_base_url}\"\n                    await logger.ainfo(info_message)\n                except ValueError:\n                    await logger.awarning(\"Error updating Ollama model options.\")\n                    build_config[\"model_name\"][\"options\"] = []\n                    build_config[\"model_name\"][\"value\"] = \"\"\n            else:\n                await logger.awarning(f\"Invalid Ollama URL: {self.ollama_base_url}\")\n                build_config[\"model_name\"][\"options\"] = []\n                build_config[\"model_name\"][\"value\"] = \"\"\n        elif field_name == \"model_name\":\n            # Refresh Ollama models when model_name field is accessed\n            if hasattr(self, \"provider\") and self.provider == \"Ollama\":\n                ollama_url = getattr(self, \"ollama_base_url\", DEFAULT_OLLAMA_URL)\n                if await is_valid_ollama_url(url=ollama_url):\n                    try:\n                        models = await get_ollama_models(\n                            base_url_value=ollama_url,\n                            desired_capability=DESIRED_CAPABILITY,\n                            json_models_key=JSON_MODELS_KEY,\n                            json_name_key=JSON_NAME_KEY,\n                            json_capabilities_key=JSON_CAPABILITIES_KEY,\n                        )\n                        build_config[\"model_name\"][\"options\"] = models\n                    except ValueError:\n                        await logger.awarning(\"Failed to refresh Ollama models.\")\n                        build_config[\"model_name\"][\"options\"] = []\n                else:\n                    build_config[\"model_name\"][\"options\"] = []\n\n            # Hide system_message for o1 models - currently unsupported\n            if field_value and field_value.startswith(\"o1\") and hasattr(self, \"provider\") and self.provider == \"OpenAI\":\n                if \"system_message\" in build_config:\n                    build_config[\"system_message\"][\"show\"] = False\n            elif \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "gemini-1.5-pro",
                  "gemini-1.5-flash",
                  "gemini-1.5-flash-8b",
                  "gemini-2.5-pro",
                  "gemini-2.5-flash",
                  "gemini-2.5-flash-lite",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash",
                  "gemini-exp-1206",
                  "gemini-2.0-flash-thinking-exp-01-21",
                  "learnlm-1.5-pro-experimental",
                  "gemma-2-2b",
                  "gemma-2-9b",
                  "gemma-2-27b"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "gemini-2.5-pro"
              },
              "ollama_base_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Ollama API URL",
                "dynamic": false,
                "info": "Endpoint of the Ollama API (Ollama only). Defaults to http://localhost:11434",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ollama_base_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "project_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "watsonx Project ID",
                "dynamic": false,
                "info": "The project ID associated with the foundation model (IBM watsonx.ai only)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "project_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "external_options": {},
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google",
                  "IBM watsonx.ai",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "WatsonxAI"
                  },
                  {
                    "icon": "Ollama"
                  }
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "selected_metadata": {
                  "icon": "GoogleGenerativeAI"
                },
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Google"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-fda3w",
        "measured": {
          "height": 367,
          "width": 320
        },
        "position": {
          "x": 589.2323796496594,
          "y": 78.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-vsYy3",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "last_updated": "2026-01-29T23:30:20.703Z",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "904f4eaebccd",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.processing.dataframe_operations.DataFrameOperationsComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "0a107780-0f52-4bcb-8d7a-169daca7a578"
              },
              "_frontend_node_folder_id": {
                "value": "f36a301c-85de-4ffe-900d-dcc3002c3a4d"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs import SortableListInput\nfrom lfx.io import BoolInput, DataFrameInput, DropdownInput, IntInput, MessageTextInput, Output, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"not contains\",\n                \"starts with\",\n                \"ends with\",\n                \"greater than\",\n                \"less than\",\n            ],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"not contains\":\n            mask = ~column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "status"
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "external_options": {},
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "not contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "VALID"
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "override_skip": false,
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "filter",
                    "name": "Filter",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-vsYy3",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1364.289711407147,
          "y": 621.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-rOcxC",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "last_updated": "2026-01-30T00:01:53.843Z",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "904f4eaebccd",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.processing.dataframe_operations.DataFrameOperationsComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "0a107780-0f52-4bcb-8d7a-169daca7a578"
              },
              "_frontend_node_folder_id": {
                "value": "f36a301c-85de-4ffe-900d-dcc3002c3a4d"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs import SortableListInput\nfrom lfx.io import BoolInput, DataFrameInput, DropdownInput, IntInput, MessageTextInput, Output, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"not contains\",\n                \"starts with\",\n                \"ends with\",\n                \"greater than\",\n                \"less than\",\n            ],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"not contains\":\n            mask = ~column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "status"
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "external_options": {},
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "not contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "INVALID"
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "override_skip": false,
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "filter",
                    "name": "Filter",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-rOcxC",
        "measured": {
          "height": 479,
          "width": 320
        },
        "position": {
          "x": 1364.289711407147,
          "y": 78.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-gYOJK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "last_updated": "2026-01-29T23:05:00.002Z",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "3cda25c3f7b5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.processing.parser.ParserComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "loop_types": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.3408367391839787,
            "template": {
              "_frontend_node_flow_id": {
                "value": "0a107780-0f52-4bcb-8d7a-169daca7a578"
              },
              "_frontend_node_folder_id": {
                "value": "f36a301c-85de-4ffe-900d-dcc3002c3a4d"
              },
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            # Use format_map with a dict that returns default_value for missing keys\n            class DefaultDict(dict):\n                def __missing__(self, key):\n                    return data.default_value or \"\"\n\n            formatted_text = self.pattern.format_map(DefaultDict(data.data))\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "is_refresh": false,
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "Text: {text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-gYOJK",
        "measured": {
          "height": 245,
          "width": 320
        },
        "position": {
          "x": 1728.7573365407086,
          "y": 424.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-ss9Iw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "agent_llm",
              "api_key",
              "base_url",
              "project_id",
              "max_output_tokens",
              "max_tokens",
              "model_kwargs",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-30T00:01:53.779Z",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "fba2d73636e5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.81"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "0a107780-0f52-4bcb-8d7a-169daca7a578"
              },
              "_frontend_node_folder_id": {
                "value": "f36a301c-85de-4ffe-900d-dcc3002c3a4d"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Anthropic",
                  "Google Generative AI",
                  "OpenAI",
                  "IBM watsonx.ai",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "WatsonxAI"
                  },
                  {
                    "icon": "Ollama"
                  }
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": false,
                "required": false,
                "selected_metadata": {
                  "icon": "GoogleGenerativeAI"
                },
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Google Generative AI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODEL_PROVIDERS_LIST,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.components.models_and_agents.memory import MemoryComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, SecretStrInput, StrInput\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"The API key to use for the model.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"The base URL of the API.\",\n            required=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"project_id\",\n            display_name=\"Project ID\",\n            info=\"The project ID of the model.\",\n            required=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            show=False,\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            if build_config is not None and field in build_config:\n                build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name_without_prefix = field_name.replace(prefix, \"\")\n                    else:\n                        field_name_without_prefix = field_name\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, field_name_without_prefix\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "input_types": [],
                "name": "model_name",
                "options": [
                  "gemma-3n-e4b-it",
                  "gemma-3-4b-it",
                  "gemma-3-1b-it",
                  "gemini-robotics-er-1.5-preview",
                  "gemini-flash-lite-latest",
                  "gemini-exp-1206",
                  "gemini-3-pro-image-preview",
                  "gemini-2.5-pro-preview-tts",
                  "gemini-2.5-flash-preview-tts",
                  "gemini-2.5-flash-lite-preview-09-2025",
                  "gemini-2.5-flash-image",
                  "gemini-2.5-computer-use-preview-10-2025",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-001",
                  "deep-research-pro-preview-12-2025"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": false,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "gemini-2.0-flash-lite"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "Act as a **Senior Data Quality Analyst**.\nYou have received a log containing ONLY the records that FAILED the validation process.\n\nYOUR TASK:\nAnalyze the errors and generate a **Technical Rejection Report** in Markdown.\nYou must distinguish between behavioral errors (e.g., typos, wrong city) and systemic errors (e.g., calculation glitches, floating-point noise).\n\nANALYSIS INSTRUCTIONS:\n1. **Grouping:** Identify which fields are failing the most (Top Offenders).\n2. **Numeric Precision Analysis:** strict check for \"Floating Point Artifacts\" (e.g., values like `547.7228000000001` or `0.300000004`). Classify these as \"Technical/Systemic Errors\".\n3. **Consistency Analysis:** Check for logical mismatches (e.g., City vs. Country).\n\nOUTPUT FORMAT (MARKDOWN):\n\n# 🚫 Data Exceptions Report\n\n## 1. Executive Summary\n* **Total Failures Analyzed:** (Count the rows)\n* **Overall Status:** (Critical / Warning / Low Risk)\n\n## 2. Top 3 Problematic Fields\n| Field Name | Approx. Frequency | Main Reason |\n| :--- | :--- | :--- |\n| (e.g., order_value) | (e.g., 15) | (e.g., Excessive decimal precision / Float noise) |\n| (e.g., city) | (e.g., 8) | (e.g., Geographic Inconsistency) |\n\n## 3. Detailed Technical Analysis\n* **Precision/Floating Point Errors:** (Write a short paragraph explaining if you found dirty float values. Cite specific examples from the log).\n* **Other Patterns:** (Mention other relevant patterns, such as dates in the future).\n\n## 4. Suggested Action Plan\n* [ ] (Action to fix the data generation script/system)\n* [ ] (Action to correct user input rules)\n\n---\n*Report generated automatically.*"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "float",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-ss9Iw",
        "measured": {
          "height": 591,
          "width": 320
        },
        "position": {
          "x": 2127.206703446151,
          "y": 78.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-imjMX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.7.3",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.127.0"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-imjMX",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 2492.485816424188,
          "y": 78.6274966040794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-HKNES",
          "node": {
            "description": "### **How to Control the Logic:**\n\nThe **Prompt** below is where you define the Agent's judgment criteria.\n\nEdit the Prompt text to change:\n1. **Definition of \"Technical Error\":** (e.g., classifying float artifacts like `0.30004` as system glitches).\n2. **Definition of \"Human Error\":** (e.g., typos, invalid dates, or city mismatches).\n3. **Report Format:** (Add or remove sections from the final Markdown output).\n\n*If business rules change (e.g., max age changes from 100 to 120), update the Prompt here.*",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 401,
        "id": "note-HKNES",
        "measured": {
          "height": 401,
          "width": 568
        },
        "position": {
          "x": -7.10772039723679,
          "y": 96.39284551888079
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 568
      },
      {
        "data": {
          "id": "Prompt Template-4UjbK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {
              "code_hash": "7382d03ce412",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.2"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.models_and_agents.prompt.PromptComponent"
            },
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.prompts.api_utils import process_prompt_template\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DefaultPromptField\nfrom lfx.io import MessageTextInput, Output, PromptInput\nfrom lfx.schema.message import Message\nfrom lfx.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "prompt",
                "value": "You are a Senior Data Quality Auditor. Your analysis must be skeptical, rigorous, and EXHAUSTIVE.\n\nINPUT DATA (JSON/TOML):\nAnalyze each field by cross-referencing the information.\n\nVALIDATION RULES (STRICT CRITERIA):\n\n1. SYNTAX AND FORMAT:\n   - customer_id: MUST follow the strict pattern \"CUST-\" followed by numbers (e.g., \"CUST-10045\").\n   - email: MUST be a syntactically valid email (user + \"@\" + domain + \".\" + extension).\n   - order_date: MUST be in YYYY-MM-DD format.\n\n2. BUSINESS RULES (LIMITS & PRECISION):\n   - age: Allowed only between 18 and 100 years old.\n   - order_value: MUST be strictly greater than 0.00.\n     - **DECIMAL PRECISION RULE:** Values MUST NOT have more than 4 decimal places.\n     - Example: \"100.1234\" is VALID. \"100.12345\" is INVALID. \"100.123400001\" is INVALID (Floating point artifact).\n   - quantity: MUST be an integer greater than or equal to 1.\n   - discount: MUST be a float between 0.00 and 0.50.\n     - **PRECISION:** Max 4 decimal places. Any floating point noise (e.g., 0.300000004) is INVALID.\n   - satisfaction_score: Integer strictly between 1 and 10.\n\n3. LOGICAL CONSISTENCY (DATA CROSS-REFERENCING):\n   - Geographic: The 'city' MUST belong to the reported 'country'.\n   - Temporal: The 'order_date' CANNOT be a future date (compare with current date context).\n\nMANDATORY OUTPUT (STRICT JSON):\nCheck ALL rules. Do NOT stop at the first error. Accumulate all violations found.\n\nIf ANY violation is found:\n{{\n    \"status\": \"INVALID\",\n    \"error_field\": \"list all failed fields separated by comma (e.g., order_value, discount)\",\n    \"description\": \"list all reasons separated by semicolon (e.g., Value has floating point noise; Discount precision error)\"\n}}\n\nIf it passes ALL rules without exception:\n{{\n    \"status\": \"VALID\",\n    \"error_field\": null,\n    \"description\": null\n}}"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-4UjbK",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 151.2002088665201,
          "y": 431.07068859101764
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-LrlkB",
          "node": {
            "description": "### ⬆️ Valid Data Here\n\nThis output contains **only** the records that passed ALL validation rules.\n\n**Suggested Destinations:**\n* Save to Production Database (Postgres/MySQL)\n* Save as \"Clean\" file (`clean_data.csv`)\n* Send to API",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-LrlkB",
        "measured": {
          "height": 324,
          "width": 494
        },
        "position": {
          "x": 1364.289711407147,
          "y": 692.227268041427
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 494
      },
      {
        "data": {
          "id": "note-KiT8V",
          "node": {
            "description": "### ⬆️ Analysis Result\n\nThe AI Agent processed the rejected data and generated a full diagnosis here.\n\n**How to view:**\n1. Click the **Playground** button (▶️) or check this component's output.\n2. The report will show:\n   * **Technical Errors:** (e.g., decimal precision/float artifacts).\n   * **Business Errors:** (e.g., wrong city, invalid age).\n   * **Action Plan:** Suggestions on how to fix them.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-KiT8V",
        "measured": {
          "height": 324,
          "width": 521
        },
        "position": {
          "x": 2492.485816424188,
          "y": 147.93140752154258
        },
        "selected": true,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "note-5mSRz",
          "node": {
            "description": "**Enhanced Features:**\n\nThis component includes modified Python code to:\n\n1.  **Temporal Context:** Dynamically injects the current date into the prompt, enabling the AI to validate rules like \"Order date cannot be in the future.\"\n2.  **Column Generation:** Automatically parses the AI's JSON response and expands it into new DataFrame columns (`status`, `error_field`, `description`), streamlining the workflow without external parsers.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 736,
        "id": "note-5mSRz",
        "measured": {
          "height": 736,
          "width": 372
        },
        "position": {
          "x": 941.6663088311432,
          "y": -48.58039455001948
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 372
      },
      {
        "data": {
          "id": "note-PxUg8",
          "node": {
            "description": "### ⚠️ Mock Data Placeholder\n\nThis component is currently loading dummy data for testing purposes.\n",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "rose"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-PxUg8",
        "measured": {
          "height": 324,
          "width": 418
        },
        "position": {
          "x": 445.79292837455773,
          "y": 528.9539372623773
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 418
      }
    ],
    "viewport": {
      "x": -2247.129668500033,
      "y": -69.73783960720277,
      "zoom": 1.1504336135332862
    }
  },
  "description": "Language Engineering Excellence.",
  "endpoint_name": null,
  "id": "0a107780-0f52-4bcb-8d7a-169daca7a578",
  "is_component": false,
  "last_tested_version": "1.7.3",
  "name": "Data Quality Validator",
  "tags": []
}